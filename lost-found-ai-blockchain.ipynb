{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":38601,"sourceType":"datasetVersion","datasetId":30279}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport numpy as np\nfrom scipy import stats\nfrom PIL import Image\nimport os\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Data augmentation for training\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# No augmentation transform (for ablation)\nno_aug_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Noise transform for robustness test\nnoise_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Validation/test transform\ntest_transform = no_aug_transform  # Alias for clarity","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:52:26.188072Z","iopub.execute_input":"2025-11-30T17:52:26.188298Z","iopub.status.idle":"2025-11-30T17:52:35.180617Z","shell.execute_reply.started":"2025-11-30T17:52:26.188277Z","shell.execute_reply":"2025-11-30T17:52:35.179724Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Custom Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, samples, transform=None):\n        self.samples = samples  # list of (path, label)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        img = Image.open(path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, target\n\n# Define relevant classes for lost-and-found items (10 classes selected)\nrelevant_classes = [\n    '003.backpack',      # Backpack\n    '033.cd',            # CD (proxy for disc-like items, e.g., wallet)\n    '041.coffee-mug',    # Mug (portable)\n    '047.computer-mouse',# Computer mouse (peripheral)\n    '067.eyeglasses',    # Eyeglasses (sunglasses proxy)\n    '101.head-phones',   # Headphones\n    '117.ipod',          # iPod (phone-like device)\n    '127.laptop-101',    # Laptop\n    '235.umbrella-101',  # Umbrella\n    '240.watch-101'      # Watch\n]\n\n# Load the Caltech-256 dataset without transform\ndataset_folder = '/kaggle/input/caltech256/256_ObjectCategories'\norig_dataset = datasets.ImageFolder(root=dataset_folder, transform=None)\n\n# Filter samples to only include relevant classes\nclass_to_idx = {cls: idx for idx, cls in enumerate(relevant_classes)}\nfull_samples = []\nfull_targets = []\nfor path, target in orig_dataset.samples:\n    class_dir = os.path.basename(os.path.dirname(path))\n    if class_dir in relevant_classes:\n        new_target = class_to_idx[class_dir]\n        full_samples.append(path)\n        full_targets.append(new_target)\n\nclasses = relevant_classes\nnum_classes = len(classes)\nprint(f\"Selected {num_classes} classes: {classes}\")\nprint(f\"Total filtered images: {len(full_samples)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:52:43.050644Z","iopub.execute_input":"2025-11-30T17:52:43.051310Z","iopub.status.idle":"2025-11-30T17:53:22.702967Z","shell.execute_reply.started":"2025-11-30T17:52:43.051285Z","shell.execute_reply":"2025-11-30T17:53:22.702329Z"}},"outputs":[{"name":"stdout","text":"Selected 10 classes: ['003.backpack', '033.cd', '041.coffee-mug', '047.computer-mouse', '067.eyeglasses', '101.head-phones', '117.ipod', '127.laptop-101', '235.umbrella-101', '240.watch-101']\nTotal filtered images: 1219\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Split indices: 70% train, 15% val, 15% test (stratified)\nindices = list(range(len(full_samples)))\ntrain_val_idx, test_idx = train_test_split(indices, test_size=0.15, stratify=full_targets, random_state=42)\ntrain_val_targets = [full_targets[i] for i in train_val_idx]\ntrain_idx, val_idx = train_test_split(train_val_idx, test_size=0.15 / 0.85, stratify=train_val_targets, random_state=42)\n\nprint(f\"Train size: {len(train_idx)} ({len(train_idx)/len(indices)*100:.1f}%)\")\nprint(f\"Val size: {len(val_idx)} ({len(val_idx)/len(indices)*100:.1f}%)\")\nprint(f\"Test size: {len(test_idx)} ({len(test_idx)/len(indices)*100:.1f}%)\")\n\n# Create split samples (path, label)\ntrain_samples = [(full_samples[i], full_targets[i]) for i in train_idx]\nval_samples = [(full_samples[i], full_targets[i]) for i in val_idx]\ntest_samples = [(full_samples[i], full_targets[i]) for i in test_idx]\n\n# Create datasets\ntrain_dataset = CustomDataset(train_samples, train_transform)\nval_dataset = CustomDataset(val_samples, test_transform)\ntest_dataset = CustomDataset(test_samples, test_transform)\nnoise_test_dataset = CustomDataset(test_samples, noise_transform)\n\n# Loaders with increased batch size and num_workers for efficiency\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\nnoise_test_loader = DataLoader(noise_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:54:15.724849Z","iopub.execute_input":"2025-11-30T17:54:15.725488Z","iopub.status.idle":"2025-11-30T17:54:15.742186Z","shell.execute_reply.started":"2025-11-30T17:54:15.725463Z","shell.execute_reply":"2025-11-30T17:54:15.741459Z"}},"outputs":[{"name":"stdout","text":"Train size: 853 (70.0%)\nVal size: 183 (15.0%)\nTest size: 183 (15.0%)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Function to get model by name (dynamic num_classes)\ndef get_model(model_name, num_classes):\n    if model_name == 'resnet50':\n        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n        params_to_optimize = list(model.fc.parameters())\n    elif model_name == 'vgg16':\n        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n        num_ftrs = model.classifier[6].in_features\n        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n        params_to_optimize = list(model.classifier[6].parameters())\n    elif model_name == 'mobilenet_v3':\n        model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n        num_ftrs = model.classifier[3].in_features\n        model.classifier[3] = nn.Linear(num_ftrs, num_classes)\n        params_to_optimize = list(model.classifier[3].parameters())\n    else:\n        raise ValueError(\"Unknown model name\")\n    \n    # Freeze all layers except the classifier\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in params_to_optimize:\n        param.requires_grad = True\n    \n    model = model.to(device)\n    return model, params_to_optimize\n\n# Training function with early stopping and validation (increased epochs/patience)\ndef train_model(model, train_loader, val_loader, criterion, optimizer, epochs=30, patience=5):\n    best_val_loss = float('inf')\n    patience_counter = 0\n    train_losses = []\n    val_losses = []\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        avg_train_loss = running_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        # Validate\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n        avg_val_loss = val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n        \n        # Early stopping\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    return train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:54:31.590749Z","iopub.execute_input":"2025-11-30T17:54:31.591023Z","iopub.status.idle":"2025-11-30T17:54:31.600877Z","shell.execute_reply.started":"2025-11-30T17:54:31.591002Z","shell.execute_reply":"2025-11-30T17:54:31.600201Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Evaluation function (unchanged, but handles more classes)\ndef evaluate_model(model, loader, classes, alpha=0.05, save_prefix=''):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    all_probs = []\n    inference_times = []\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            start_time = time.time()\n            outputs = model(inputs)\n            end_time = time.time()\n            _, predicted = torch.max(outputs.data, 1)\n            probs = torch.softmax(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n            inference_times.append((end_time - start_time) / inputs.size(0))\n    all_labels = np.array(all_labels)\n    all_preds = np.array(all_preds)\n    all_probs = np.array(all_probs)\n    # Metrics\n    accuracy = np.mean(all_preds == all_labels)\n    precision = precision_score(all_labels, all_preds, average='macro')\n    recall = recall_score(all_labels, all_preds, average='macro')\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    avg_inference_time = np.mean(inference_times)\n    # AUC\n    bin_labels = label_binarize(all_labels, classes=range(len(classes)))\n    auc_macro = roc_auc_score(bin_labels, all_probs, average='macro', multi_class='ovr')\n    auc_per_class = roc_auc_score(bin_labels, all_probs, average=None, multi_class='ovr')\n    # Confidence intervals (normal approximation)\n    n = len(all_labels)\n    def ci(metric):\n        se = np.sqrt(metric * (1 - metric) / n if n > 0 else 0)\n        h = se * stats.norm.ppf(1 - alpha/2)\n        return h\n    acc_ci = ci(accuracy) * 100\n    prec_ci = ci(precision) * 100\n    recall_ci = ci(recall) * 100\n    f1_ci = ci(f1) * 100\n    print(f\"Accuracy: {accuracy*100:.2f}% ± {acc_ci:.2f}%\")\n    print(f\"Precision: {precision*100:.2f}% ± {prec_ci:.2f}%\")\n    print(f\"Recall: {recall*100:.2f}% ± {recall_ci:.2f}%\")\n    print(f\"F1-score: {f1*100:.2f}% ± {f1_ci:.2f}%\")\n    print(f\"Macro AUC: {auc_macro:.4f}\")\n    print(f\"Per-class AUC: {', '.join([f'{classes[i]}: {auc_per_class[i]:.4f}' for i in range(len(classes))])}\")\n    print(f\"Average Inference Time: {avg_inference_time:.4f}s per image\")\n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10,8), dpi=300)  # Larger for more classes\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.xticks(rotation=45, ha='right')\n    plt.yticks(rotation=0)\n    plt.savefig(f'{save_prefix}confusion_matrix_300dpi.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    # Per-class metrics bar chart\n    class_prec = precision_score(all_labels, all_preds, average=None)\n    class_recall = recall_score(all_labels, all_preds, average=None)\n    class_f1 = f1_score(all_labels, all_preds, average=None)\n    x = np.arange(len(classes))\n    width = 0.2\n    plt.figure(figsize=(12,6), dpi=300)  # Larger for more classes\n    plt.bar(x - width, class_prec*100, width, label='Precision')\n    plt.bar(x, class_recall*100, width, label='Recall')\n    plt.bar(x + width, class_f1*100, width, label='F1-score')\n    plt.xticks(x, classes, rotation=45, ha='right')\n    plt.ylabel('Score (%)')\n    plt.title('Per-Class Metrics')\n    plt.legend()\n    plt.savefig(f'{save_prefix}per_class_metrics_300dpi.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    # ROC curves\n    plt.figure(figsize=(10,8), dpi=300)\n    for i in range(len(classes)):\n        fpr, tpr, _ = roc_curve(bin_labels[:, i], all_probs[:, i])\n        plt.plot(fpr, tpr, label=f'{classes[i]} (AUC = {auc_per_class[i]:.2f})')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curves')\n    plt.legend(loc='lower right', fontsize='small')\n    plt.savefig(f'{save_prefix}roc_curves_300dpi.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    return accuracy, precision, recall, f1, auc_macro, avg_inference_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:54:36.968604Z","iopub.execute_input":"2025-11-30T17:54:36.969221Z","iopub.status.idle":"2025-11-30T17:54:36.982650Z","shell.execute_reply.started":"2025-11-30T17:54:36.969197Z","shell.execute_reply":"2025-11-30T17:54:36.981843Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Function to run 5-fold CV and report mean ± std (updated for larger dataset)\ndef run_cv(model_name, train_transform, classes, num_classes, patience=5, epochs=30, save_prefix=''):\n    print(f\"\\nRunning 5-fold CV for {model_name} with augmentation: {train_transform != test_transform}\")\n    # Prepare train_val data for CV\n    train_val_samples = [(full_samples[i], full_targets[i]) for i in train_val_idx]\n    train_val_targets_cv = [full_targets[i] for i in train_val_idx]  # For stratify\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    fold_accuracies = []\n    fold_precisions = []\n    fold_recalls = []\n    fold_f1s = []\n    fold_aucs = []\n    for fold, (fold_train_idx, fold_val_idx) in enumerate(skf.split(range(len(train_val_idx)), train_val_targets_cv)):\n        print(f\"Fold {fold+1}\")\n        # Create fold datasets\n        fold_train_samples = [train_val_samples[j] for j in fold_train_idx]\n        fold_val_samples = [train_val_samples[j] for j in fold_val_idx]\n        fold_train_dataset = CustomDataset(fold_train_samples, train_transform)\n        fold_val_dataset = CustomDataset(fold_val_samples, test_transform)\n        fold_train_loader = DataLoader(fold_train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n        fold_val_loader = DataLoader(fold_val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n        # Get model\n        model, params_to_optimize = get_model(model_name, num_classes)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(params_to_optimize, lr=0.001)\n        # Train with early stopping\n        train_losses, val_losses = train_model(model, fold_train_loader, fold_val_loader, criterion, optimizer, epochs, patience)\n        # Plot learning curve for fold\n        plt.figure(figsize=(8,6), dpi=300)\n        plt.plot(train_losses, label='Train Loss')\n        plt.plot(val_losses, label='Val Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.title(f'Learning Curve - {model_name} Fold {fold+1}')\n        plt.legend()\n        plt.savefig(f'{save_prefix}{model_name}_fold{fold+1}_learning_curve_300dpi.png', dpi=300)\n        plt.close()\n        # Evaluate on fold val\n        acc, prec, rec, f1, auc, _ = evaluate_model(model, fold_val_loader, classes, save_prefix=f'{save_prefix}{model_name}_fold{fold+1}_')\n        fold_accuracies.append(acc)\n        fold_precisions.append(prec)\n        fold_recalls.append(rec)\n        fold_f1s.append(f1)\n        fold_aucs.append(auc)\n    # Report mean ± std\n    print(\"\\n5-Fold CV Results:\")\n    print(f\"Accuracy: {np.mean(fold_accuracies)*100:.2f}% ± {np.std(fold_accuracies)*100:.2f}%\")\n    print(f\"Precision: {np.mean(fold_precisions)*100:.2f}% ± {np.std(fold_precisions)*100:.2f}%\")\n    print(f\"Recall: {np.mean(fold_recalls)*100:.2f}% ± {np.std(fold_recalls)*100:.2f}%\")\n    print(f\"F1-score: {np.mean(fold_f1s)*100:.2f}% ± {np.std(fold_f1s)*100:.2f}%\")\n    print(f\"Macro AUC: {np.mean(fold_aucs):.4f} ± {np.std(fold_aucs):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:55:01.492508Z","iopub.execute_input":"2025-11-30T17:55:01.493254Z","iopub.status.idle":"2025-11-30T17:55:01.503265Z","shell.execute_reply.started":"2025-11-30T17:55:01.493228Z","shell.execute_reply":"2025-11-30T17:55:01.502608Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Main execution\nmodel_names = ['resnet50', 'vgg16', 'mobilenet_v3']\n\n# Run CV for each model with augmentation\nfor model_name in model_names:\n    run_cv(model_name, train_transform, classes, num_classes, save_prefix='aug_')\n\n# Ablation: Without augmentation\nfor model_name in model_names:\n    run_cv(model_name, no_aug_transform, classes, num_classes, save_prefix='noaug_')\n\n# Final evaluation on holdout test (using best model, e.g., resnet50 trained on full train+val)\nprint(\"\\nTraining final model (ResNet50) on full train+val and evaluating on test/noise test\")\ntrain_val_samples_full = [(full_samples[i], full_targets[i]) for i in train_val_idx]\ntrain_val_dataset_full = CustomDataset(train_val_samples_full, train_transform)\ntrain_val_loader_full = DataLoader(train_val_dataset_full, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n\nmodel, params_to_optimize = get_model('resnet50', num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(params_to_optimize, lr=0.001)\n\n# Train on full train_val (fixed epochs, increased to 20)\nmodel.train()\nfor epoch in range(20):\n    running_loss = 0.0\n    for inputs, labels in train_val_loader_full:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    print(f\"Final Train Epoch {epoch+1}, Loss: {running_loss / len(train_val_loader_full):.4f}\")\n\n# Evaluate on test\nprint(\"\\nHoldout Test Evaluation:\")\nevaluate_model(model, test_loader, classes, save_prefix='final_test_')\n\n# Evaluate on noise test (robustness)\nprint(\"\\nNoise Test Evaluation (Robustness to Gaussian Blur):\")\nevaluate_model(model, noise_test_loader, classes, save_prefix='noise_test_')\n\n# List all generated PNG files at the end\nprint(\"\\nGenerated PNG files:\")\npng_files = [f for f in os.listdir('.') if f.endswith('.png')]\nprint('\\n'.join(sorted(png_files)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:55:08.153619Z","iopub.execute_input":"2025-11-30T17:55:08.153896Z","iopub.status.idle":"2025-11-30T18:59:49.746323Z","shell.execute_reply.started":"2025-11-30T17:55:08.153872Z","shell.execute_reply":"2025-11-30T18:59:49.745616Z"}},"outputs":[{"name":"stdout","text":"\nRunning 5-fold CV for resnet50 with augmentation: True\nFold 1\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 215MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.7684, Val Loss: 0.9979\nEpoch 2/30, Train Loss: 0.9255, Val Loss: 0.5717\nEpoch 3/30, Train Loss: 0.5894, Val Loss: 0.4089\nEpoch 4/30, Train Loss: 0.4292, Val Loss: 0.3083\nEpoch 5/30, Train Loss: 0.3615, Val Loss: 0.2708\nEpoch 6/30, Train Loss: 0.3296, Val Loss: 0.2315\nEpoch 7/30, Train Loss: 0.2714, Val Loss: 0.2213\nEpoch 8/30, Train Loss: 0.2506, Val Loss: 0.2109\nEpoch 9/30, Train Loss: 0.2483, Val Loss: 0.1977\nEpoch 10/30, Train Loss: 0.2223, Val Loss: 0.1776\nEpoch 11/30, Train Loss: 0.2080, Val Loss: 0.1735\nEpoch 12/30, Train Loss: 0.1915, Val Loss: 0.1861\nEpoch 13/30, Train Loss: 0.1763, Val Loss: 0.1618\nEpoch 14/30, Train Loss: 0.1783, Val Loss: 0.1662\nEpoch 15/30, Train Loss: 0.1745, Val Loss: 0.1683\nEpoch 16/30, Train Loss: 0.1599, Val Loss: 0.1562\nEpoch 17/30, Train Loss: 0.1601, Val Loss: 0.1587\nEpoch 18/30, Train Loss: 0.1482, Val Loss: 0.1507\nEpoch 19/30, Train Loss: 0.1287, Val Loss: 0.1408\nEpoch 20/30, Train Loss: 0.1351, Val Loss: 0.1412\nEpoch 21/30, Train Loss: 0.1176, Val Loss: 0.1428\nEpoch 22/30, Train Loss: 0.1157, Val Loss: 0.1366\nEpoch 23/30, Train Loss: 0.1179, Val Loss: 0.1402\nEpoch 24/30, Train Loss: 0.1261, Val Loss: 0.1243\nEpoch 25/30, Train Loss: 0.1156, Val Loss: 0.1371\nEpoch 26/30, Train Loss: 0.1043, Val Loss: 0.1238\nEpoch 27/30, Train Loss: 0.1134, Val Loss: 0.1420\nEpoch 28/30, Train Loss: 0.0996, Val Loss: 0.1187\nEpoch 29/30, Train Loss: 0.1025, Val Loss: 0.1394\nEpoch 30/30, Train Loss: 0.0909, Val Loss: 0.1175\nAccuracy: 96.15% ± 2.61%\nPrecision: 96.11% ± 2.63%\nRecall: 95.61% ± 2.78%\nF1-score: 95.70% ± 2.76%\nMacro AUC: 0.9990\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9982, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9974, 067.eyeglasses: 0.9985, 101.head-phones: 0.9986, 117.ipod: 0.9976, 127.laptop-101: 0.9995, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 2\nEpoch 1/30, Train Loss: 1.7414, Val Loss: 0.9745\nEpoch 2/30, Train Loss: 0.8923, Val Loss: 0.5047\nEpoch 3/30, Train Loss: 0.5688, Val Loss: 0.3592\nEpoch 4/30, Train Loss: 0.4265, Val Loss: 0.2950\nEpoch 5/30, Train Loss: 0.3819, Val Loss: 0.2298\nEpoch 6/30, Train Loss: 0.3186, Val Loss: 0.2073\nEpoch 7/30, Train Loss: 0.2793, Val Loss: 0.1857\nEpoch 8/30, Train Loss: 0.2465, Val Loss: 0.1730\nEpoch 9/30, Train Loss: 0.2537, Val Loss: 0.1661\nEpoch 10/30, Train Loss: 0.2128, Val Loss: 0.1509\nEpoch 11/30, Train Loss: 0.2107, Val Loss: 0.1566\nEpoch 12/30, Train Loss: 0.2036, Val Loss: 0.1514\nEpoch 13/30, Train Loss: 0.1761, Val Loss: 0.1483\nEpoch 14/30, Train Loss: 0.1655, Val Loss: 0.1436\nEpoch 15/30, Train Loss: 0.1654, Val Loss: 0.1307\nEpoch 16/30, Train Loss: 0.1576, Val Loss: 0.1384\nEpoch 17/30, Train Loss: 0.1506, Val Loss: 0.1307\nEpoch 18/30, Train Loss: 0.1679, Val Loss: 0.1328\nEpoch 19/30, Train Loss: 0.1326, Val Loss: 0.1308\nEpoch 20/30, Train Loss: 0.1193, Val Loss: 0.1140\nEpoch 21/30, Train Loss: 0.1195, Val Loss: 0.1287\nEpoch 22/30, Train Loss: 0.1243, Val Loss: 0.1154\nEpoch 23/30, Train Loss: 0.1276, Val Loss: 0.1181\nEpoch 24/30, Train Loss: 0.1209, Val Loss: 0.1235\nEpoch 25/30, Train Loss: 0.1132, Val Loss: 0.1199\nEarly stopping at epoch 25\nAccuracy: 97.10% ± 2.29%\nPrecision: 96.55% ± 2.49%\nRecall: 96.67% ± 2.44%\nF1-score: 96.54% ± 2.49%\nMacro AUC: 0.9994\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9997, 041.coffee-mug: 0.9993, 047.computer-mouse: 0.9987, 067.eyeglasses: 0.9978, 101.head-phones: 0.9995, 117.ipod: 0.9992, 127.laptop-101: 1.0000, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0003s per image\nFold 3\nEpoch 1/30, Train Loss: 1.7849, Val Loss: 1.0509\nEpoch 2/30, Train Loss: 0.9308, Val Loss: 0.5812\nEpoch 3/30, Train Loss: 0.5711, Val Loss: 0.4173\nEpoch 4/30, Train Loss: 0.4408, Val Loss: 0.3832\nEpoch 5/30, Train Loss: 0.3625, Val Loss: 0.2854\nEpoch 6/30, Train Loss: 0.3121, Val Loss: 0.2788\nEpoch 7/30, Train Loss: 0.2829, Val Loss: 0.2436\nEpoch 8/30, Train Loss: 0.2403, Val Loss: 0.2280\nEpoch 9/30, Train Loss: 0.2457, Val Loss: 0.2216\nEpoch 10/30, Train Loss: 0.2040, Val Loss: 0.2058\nEpoch 11/30, Train Loss: 0.1981, Val Loss: 0.2069\nEpoch 12/30, Train Loss: 0.1867, Val Loss: 0.1908\nEpoch 13/30, Train Loss: 0.2031, Val Loss: 0.1941\nEpoch 14/30, Train Loss: 0.1762, Val Loss: 0.1761\nEpoch 15/30, Train Loss: 0.1620, Val Loss: 0.1959\nEpoch 16/30, Train Loss: 0.1484, Val Loss: 0.1646\nEpoch 17/30, Train Loss: 0.1466, Val Loss: 0.1802\nEpoch 18/30, Train Loss: 0.1295, Val Loss: 0.1590\nEpoch 19/30, Train Loss: 0.1253, Val Loss: 0.1725\nEpoch 20/30, Train Loss: 0.1340, Val Loss: 0.1609\nEpoch 21/30, Train Loss: 0.1278, Val Loss: 0.1702\nEpoch 22/30, Train Loss: 0.1081, Val Loss: 0.1629\nEpoch 23/30, Train Loss: 0.1115, Val Loss: 0.1557\nEpoch 24/30, Train Loss: 0.0977, Val Loss: 0.1566\nEpoch 25/30, Train Loss: 0.1137, Val Loss: 0.1526\nEpoch 26/30, Train Loss: 0.1051, Val Loss: 0.1578\nEpoch 27/30, Train Loss: 0.1064, Val Loss: 0.1537\nEpoch 28/30, Train Loss: 0.0881, Val Loss: 0.1551\nEpoch 29/30, Train Loss: 0.0795, Val Loss: 0.1490\nEpoch 30/30, Train Loss: 0.0931, Val Loss: 0.1568\nAccuracy: 95.17% ± 2.92%\nPrecision: 94.60% ± 3.08%\nRecall: 94.28% ± 3.16%\nF1-score: 94.36% ± 3.14%\nMacro AUC: 0.9984\nPer-class AUC: 003.backpack: 0.9998, 033.cd: 0.9963, 041.coffee-mug: 0.9985, 047.computer-mouse: 0.9987, 067.eyeglasses: 0.9963, 101.head-phones: 0.9998, 117.ipod: 0.9956, 127.laptop-101: 0.9998, 235.umbrella-101: 0.9992, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 4\nEpoch 1/30, Train Loss: 1.7668, Val Loss: 1.0124\nEpoch 2/30, Train Loss: 0.9257, Val Loss: 0.5543\nEpoch 3/30, Train Loss: 0.5726, Val Loss: 0.3613\nEpoch 4/30, Train Loss: 0.4314, Val Loss: 0.2885\nEpoch 5/30, Train Loss: 0.3622, Val Loss: 0.2469\nEpoch 6/30, Train Loss: 0.3258, Val Loss: 0.2119\nEpoch 7/30, Train Loss: 0.2970, Val Loss: 0.2014\nEpoch 8/30, Train Loss: 0.2539, Val Loss: 0.1874\nEpoch 9/30, Train Loss: 0.2474, Val Loss: 0.1992\nEpoch 10/30, Train Loss: 0.2313, Val Loss: 0.1682\nEpoch 11/30, Train Loss: 0.2105, Val Loss: 0.1646\nEpoch 12/30, Train Loss: 0.1958, Val Loss: 0.1519\nEpoch 13/30, Train Loss: 0.1608, Val Loss: 0.1474\nEpoch 14/30, Train Loss: 0.1658, Val Loss: 0.1464\nEpoch 15/30, Train Loss: 0.1589, Val Loss: 0.1494\nEpoch 16/30, Train Loss: 0.1448, Val Loss: 0.1355\nEpoch 17/30, Train Loss: 0.1707, Val Loss: 0.1351\nEpoch 18/30, Train Loss: 0.1377, Val Loss: 0.1409\nEpoch 19/30, Train Loss: 0.1351, Val Loss: 0.1388\nEpoch 20/30, Train Loss: 0.1317, Val Loss: 0.1328\nEpoch 21/30, Train Loss: 0.1199, Val Loss: 0.1290\nEpoch 22/30, Train Loss: 0.1132, Val Loss: 0.1308\nEpoch 23/30, Train Loss: 0.1056, Val Loss: 0.1235\nEpoch 24/30, Train Loss: 0.1130, Val Loss: 0.1221\nEpoch 25/30, Train Loss: 0.0987, Val Loss: 0.1288\nEpoch 26/30, Train Loss: 0.0948, Val Loss: 0.1319\nEpoch 27/30, Train Loss: 0.0966, Val Loss: 0.1191\nEpoch 28/30, Train Loss: 0.0967, Val Loss: 0.1246\nEpoch 29/30, Train Loss: 0.0908, Val Loss: 0.1198\nEpoch 30/30, Train Loss: 0.0932, Val Loss: 0.1270\nAccuracy: 94.69% ± 3.06%\nPrecision: 94.92% ± 2.99%\nRecall: 94.00% ± 3.24%\nF1-score: 94.02% ± 3.23%\nMacro AUC: 0.9988\nPer-class AUC: 003.backpack: 0.9989, 033.cd: 1.0000, 041.coffee-mug: 0.9997, 047.computer-mouse: 0.9987, 067.eyeglasses: 0.9941, 101.head-phones: 0.9993, 117.ipod: 0.9977, 127.laptop-101: 1.0000, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0003s per image\nFold 5\nEpoch 1/30, Train Loss: 1.7292, Val Loss: 0.9461\nEpoch 2/30, Train Loss: 0.8950, Val Loss: 0.5236\nEpoch 3/30, Train Loss: 0.5736, Val Loss: 0.3820\nEpoch 4/30, Train Loss: 0.4225, Val Loss: 0.3136\nEpoch 5/30, Train Loss: 0.3503, Val Loss: 0.2784\nEpoch 6/30, Train Loss: 0.3161, Val Loss: 0.2582\nEpoch 7/30, Train Loss: 0.2632, Val Loss: 0.2411\nEpoch 8/30, Train Loss: 0.2597, Val Loss: 0.2369\nEpoch 9/30, Train Loss: 0.2133, Val Loss: 0.2266\nEpoch 10/30, Train Loss: 0.2014, Val Loss: 0.2081\nEpoch 11/30, Train Loss: 0.1831, Val Loss: 0.2058\nEpoch 12/30, Train Loss: 0.1867, Val Loss: 0.2160\nEpoch 13/30, Train Loss: 0.1655, Val Loss: 0.1844\nEpoch 14/30, Train Loss: 0.1687, Val Loss: 0.1947\nEpoch 15/30, Train Loss: 0.1514, Val Loss: 0.1989\nEpoch 16/30, Train Loss: 0.1322, Val Loss: 0.1857\nEpoch 17/30, Train Loss: 0.1525, Val Loss: 0.1920\nEpoch 18/30, Train Loss: 0.1336, Val Loss: 0.1925\nEarly stopping at epoch 18\nAccuracy: 92.75% ± 3.53%\nPrecision: 92.68% ± 3.55%\nRecall: 92.75% ± 3.53%\nF1-score: 92.43% ± 3.60%\nMacro AUC: 0.9970\nPer-class AUC: 003.backpack: 0.9969, 033.cd: 0.9978, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9935, 067.eyeglasses: 0.9989, 101.head-phones: 0.9882, 117.ipod: 0.9959, 127.laptop-101: 0.9993, 235.umbrella-101: 0.9997, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\n\n5-Fold CV Results:\nAccuracy: 95.17% ± 1.47%\nPrecision: 94.97% ± 1.35%\nRecall: 94.66% ± 1.35%\nF1-score: 94.61% ± 1.42%\nMacro AUC: 0.9985 ± 0.0008\n\nRunning 5-fold CV for vgg16 with augmentation: True\nFold 1\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 210MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.2379, Val Loss: 0.3613\nEpoch 2/30, Train Loss: 0.4445, Val Loss: 0.2772\nEpoch 3/30, Train Loss: 0.3382, Val Loss: 0.2284\nEpoch 4/30, Train Loss: 0.2723, Val Loss: 0.2131\nEpoch 5/30, Train Loss: 0.2376, Val Loss: 0.2067\nEpoch 6/30, Train Loss: 0.2105, Val Loss: 0.2172\nEpoch 7/30, Train Loss: 0.2232, Val Loss: 0.2050\nEpoch 8/30, Train Loss: 0.1794, Val Loss: 0.2188\nEpoch 9/30, Train Loss: 0.1538, Val Loss: 0.2066\nEpoch 10/30, Train Loss: 0.1744, Val Loss: 0.2095\nEpoch 11/30, Train Loss: 0.1550, Val Loss: 0.1874\nEpoch 12/30, Train Loss: 0.1307, Val Loss: 0.2080\nEpoch 13/30, Train Loss: 0.1256, Val Loss: 0.1959\nEpoch 14/30, Train Loss: 0.1365, Val Loss: 0.2003\nEpoch 15/30, Train Loss: 0.1240, Val Loss: 0.1929\nEpoch 16/30, Train Loss: 0.1344, Val Loss: 0.1902\nEarly stopping at epoch 16\nAccuracy: 93.27% ± 3.41%\nPrecision: 93.39% ± 3.38%\nRecall: 92.66% ± 3.54%\nF1-score: 92.87% ± 3.50%\nMacro AUC: 0.9976\nPer-class AUC: 003.backpack: 0.9978, 033.cd: 0.9988, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9912, 067.eyeglasses: 0.9985, 101.head-phones: 0.9975, 117.ipod: 0.9928, 127.laptop-101: 0.9995, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\nFold 2\nEpoch 1/30, Train Loss: 1.2967, Val Loss: 0.3600\nEpoch 2/30, Train Loss: 0.4494, Val Loss: 0.1951\nEpoch 3/30, Train Loss: 0.3105, Val Loss: 0.1572\nEpoch 4/30, Train Loss: 0.2732, Val Loss: 0.1522\nEpoch 5/30, Train Loss: 0.2353, Val Loss: 0.1339\nEpoch 6/30, Train Loss: 0.2116, Val Loss: 0.1401\nEpoch 7/30, Train Loss: 0.2274, Val Loss: 0.1339\nEpoch 8/30, Train Loss: 0.1993, Val Loss: 0.1356\nEpoch 9/30, Train Loss: 0.1987, Val Loss: 0.1267\nEpoch 10/30, Train Loss: 0.1594, Val Loss: 0.1245\nEpoch 11/30, Train Loss: 0.1392, Val Loss: 0.1180\nEpoch 12/30, Train Loss: 0.1401, Val Loss: 0.1203\nEpoch 13/30, Train Loss: 0.1328, Val Loss: 0.1137\nEpoch 14/30, Train Loss: 0.1142, Val Loss: 0.1130\nEpoch 15/30, Train Loss: 0.1456, Val Loss: 0.1058\nEpoch 16/30, Train Loss: 0.1098, Val Loss: 0.1136\nEpoch 17/30, Train Loss: 0.1149, Val Loss: 0.1125\nEpoch 18/30, Train Loss: 0.1129, Val Loss: 0.1061\nEpoch 19/30, Train Loss: 0.0969, Val Loss: 0.1215\nEpoch 20/30, Train Loss: 0.1048, Val Loss: 0.1094\nEarly stopping at epoch 20\nAccuracy: 95.17% ± 2.92%\nPrecision: 94.91% ± 2.99%\nRecall: 95.06% ± 2.95%\nF1-score: 94.92% ± 2.99%\nMacro AUC: 0.9989\nPer-class AUC: 003.backpack: 0.9998, 033.cd: 1.0000, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9990, 067.eyeglasses: 0.9996, 101.head-phones: 0.9960, 117.ipod: 0.9952, 127.laptop-101: 0.9995, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\nFold 3\nEpoch 1/30, Train Loss: 1.1742, Val Loss: 0.4203\nEpoch 2/30, Train Loss: 0.4041, Val Loss: 0.3085\nEpoch 3/30, Train Loss: 0.3042, Val Loss: 0.2856\nEpoch 4/30, Train Loss: 0.2466, Val Loss: 0.2648\nEpoch 5/30, Train Loss: 0.2155, Val Loss: 0.2540\nEpoch 6/30, Train Loss: 0.1833, Val Loss: 0.2537\nEpoch 7/30, Train Loss: 0.1946, Val Loss: 0.2491\nEpoch 8/30, Train Loss: 0.1605, Val Loss: 0.2431\nEpoch 9/30, Train Loss: 0.1740, Val Loss: 0.2286\nEpoch 10/30, Train Loss: 0.1512, Val Loss: 0.2150\nEpoch 11/30, Train Loss: 0.1316, Val Loss: 0.2502\nEpoch 12/30, Train Loss: 0.1328, Val Loss: 0.2266\nEpoch 13/30, Train Loss: 0.1376, Val Loss: 0.2171\nEpoch 14/30, Train Loss: 0.1075, Val Loss: 0.2282\nEpoch 15/30, Train Loss: 0.1222, Val Loss: 0.2206\nEarly stopping at epoch 15\nAccuracy: 94.20% ± 3.18%\nPrecision: 94.55% ± 3.09%\nRecall: 93.85% ± 3.27%\nF1-score: 94.00% ± 3.24%\nMacro AUC: 0.9977\nPer-class AUC: 003.backpack: 0.9994, 033.cd: 0.9867, 041.coffee-mug: 0.9989, 047.computer-mouse: 0.9997, 067.eyeglasses: 1.0000, 101.head-phones: 0.9976, 117.ipod: 0.9985, 127.laptop-101: 1.0000, 235.umbrella-101: 0.9979, 240.watch-101: 0.9988\nAverage Inference Time: 0.0001s per image\nFold 4\nEpoch 1/30, Train Loss: 1.2891, Val Loss: 0.3518\nEpoch 2/30, Train Loss: 0.4573, Val Loss: 0.1898\nEpoch 3/30, Train Loss: 0.3167, Val Loss: 0.1710\nEpoch 4/30, Train Loss: 0.2557, Val Loss: 0.1461\nEpoch 5/30, Train Loss: 0.2501, Val Loss: 0.1404\nEpoch 6/30, Train Loss: 0.2284, Val Loss: 0.1381\nEpoch 7/30, Train Loss: 0.2061, Val Loss: 0.1379\nEpoch 8/30, Train Loss: 0.1803, Val Loss: 0.1267\nEpoch 9/30, Train Loss: 0.1830, Val Loss: 0.1232\nEpoch 10/30, Train Loss: 0.1587, Val Loss: 0.1290\nEpoch 11/30, Train Loss: 0.1384, Val Loss: 0.1307\nEpoch 12/30, Train Loss: 0.1801, Val Loss: 0.1283\nEpoch 13/30, Train Loss: 0.1281, Val Loss: 0.1234\nEpoch 14/30, Train Loss: 0.1382, Val Loss: 0.1304\nEarly stopping at epoch 14\nAccuracy: 96.14% ± 2.63%\nPrecision: 95.98% ± 2.68%\nRecall: 95.69% ± 2.77%\nF1-score: 95.73% ± 2.76%\nMacro AUC: 0.9986\nPer-class AUC: 003.backpack: 0.9992, 033.cd: 0.9978, 041.coffee-mug: 0.9990, 047.computer-mouse: 0.9984, 067.eyeglasses: 0.9989, 101.head-phones: 1.0000, 117.ipod: 0.9926, 127.laptop-101: 1.0000, 235.umbrella-101: 0.9997, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\nFold 5\nEpoch 1/30, Train Loss: 1.2297, Val Loss: 0.3461\nEpoch 2/30, Train Loss: 0.4031, Val Loss: 0.2409\nEpoch 3/30, Train Loss: 0.2880, Val Loss: 0.2130\nEpoch 4/30, Train Loss: 0.2830, Val Loss: 0.2157\nEpoch 5/30, Train Loss: 0.2259, Val Loss: 0.1965\nEpoch 6/30, Train Loss: 0.2101, Val Loss: 0.1964\nEpoch 7/30, Train Loss: 0.1913, Val Loss: 0.1884\nEpoch 8/30, Train Loss: 0.1874, Val Loss: 0.1861\nEpoch 9/30, Train Loss: 0.1662, Val Loss: 0.1859\nEpoch 10/30, Train Loss: 0.1560, Val Loss: 0.1891\nEpoch 11/30, Train Loss: 0.1582, Val Loss: 0.1880\nEpoch 12/30, Train Loss: 0.1402, Val Loss: 0.1805\nEpoch 13/30, Train Loss: 0.1389, Val Loss: 0.1824\nEpoch 14/30, Train Loss: 0.1373, Val Loss: 0.1685\nEpoch 15/30, Train Loss: 0.1031, Val Loss: 0.1849\nEpoch 16/30, Train Loss: 0.1122, Val Loss: 0.1770\nEpoch 17/30, Train Loss: 0.1092, Val Loss: 0.1770\nEpoch 18/30, Train Loss: 0.0897, Val Loss: 0.1749\nEpoch 19/30, Train Loss: 0.1092, Val Loss: 0.1733\nEarly stopping at epoch 19\nAccuracy: 94.20% ± 3.18%\nPrecision: 94.23% ± 3.18%\nRecall: 94.39% ± 3.14%\nF1-score: 94.16% ± 3.19%\nMacro AUC: 0.9975\nPer-class AUC: 003.backpack: 0.9991, 033.cd: 0.9963, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9990, 067.eyeglasses: 0.9996, 101.head-phones: 0.9934, 117.ipod: 0.9880, 127.laptop-101: 0.9993, 235.umbrella-101: 1.0000, 240.watch-101: 0.9998\nAverage Inference Time: 0.0001s per image\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n","output_type":"stream"},{"name":"stdout","text":"\n5-Fold CV Results:\nAccuracy: 94.60% ± 0.98%\nPrecision: 94.61% ± 0.85%\nRecall: 94.33% ± 1.04%\nF1-score: 94.33% ± 0.96%\nMacro AUC: 0.9981 ± 0.0006\n\nRunning 5-fold CV for mobilenet_v3 with augmentation: True\nFold 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21.1M/21.1M [00:00<00:00, 118MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 1.7545, Val Loss: 0.9038\nEpoch 2/30, Train Loss: 0.8822, Val Loss: 0.4563\nEpoch 3/30, Train Loss: 0.5495, Val Loss: 0.3183\nEpoch 4/30, Train Loss: 0.4117, Val Loss: 0.2650\nEpoch 5/30, Train Loss: 0.3448, Val Loss: 0.2364\nEpoch 6/30, Train Loss: 0.2802, Val Loss: 0.2165\nEpoch 7/30, Train Loss: 0.2700, Val Loss: 0.2024\nEpoch 8/30, Train Loss: 0.2326, Val Loss: 0.1907\nEpoch 9/30, Train Loss: 0.2171, Val Loss: 0.1833\nEpoch 10/30, Train Loss: 0.1859, Val Loss: 0.1793\nEpoch 11/30, Train Loss: 0.1862, Val Loss: 0.1763\nEpoch 12/30, Train Loss: 0.1639, Val Loss: 0.1722\nEpoch 13/30, Train Loss: 0.1484, Val Loss: 0.1692\nEpoch 14/30, Train Loss: 0.1344, Val Loss: 0.1653\nEpoch 15/30, Train Loss: 0.1458, Val Loss: 0.1589\nEpoch 16/30, Train Loss: 0.1254, Val Loss: 0.1568\nEpoch 17/30, Train Loss: 0.1132, Val Loss: 0.1548\nEpoch 18/30, Train Loss: 0.1113, Val Loss: 0.1522\nEpoch 19/30, Train Loss: 0.1072, Val Loss: 0.1516\nEpoch 20/30, Train Loss: 0.1028, Val Loss: 0.1511\nEpoch 21/30, Train Loss: 0.1005, Val Loss: 0.1481\nEpoch 22/30, Train Loss: 0.0906, Val Loss: 0.1459\nEpoch 23/30, Train Loss: 0.0901, Val Loss: 0.1439\nEpoch 24/30, Train Loss: 0.0848, Val Loss: 0.1438\nEpoch 25/30, Train Loss: 0.0834, Val Loss: 0.1441\nEpoch 26/30, Train Loss: 0.0758, Val Loss: 0.1449\nEpoch 27/30, Train Loss: 0.0678, Val Loss: 0.1450\nEpoch 28/30, Train Loss: 0.0703, Val Loss: 0.1435\nEpoch 29/30, Train Loss: 0.0680, Val Loss: 0.1437\nEpoch 30/30, Train Loss: 0.0634, Val Loss: 0.1476\nAccuracy: 95.67% ± 2.77%\nPrecision: 95.61% ± 2.78%\nRecall: 95.35% ± 2.86%\nF1-score: 95.39% ± 2.85%\nMacro AUC: 0.9981\nPer-class AUC: 003.backpack: 0.9998, 033.cd: 0.9988, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9938, 067.eyeglasses: 0.9989, 101.head-phones: 0.9995, 117.ipod: 0.9912, 127.laptop-101: 0.9985, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 2\nEpoch 1/30, Train Loss: 1.8143, Val Loss: 1.0016\nEpoch 2/30, Train Loss: 0.8981, Val Loss: 0.4921\nEpoch 3/30, Train Loss: 0.5668, Val Loss: 0.3439\nEpoch 4/30, Train Loss: 0.4222, Val Loss: 0.2914\nEpoch 5/30, Train Loss: 0.3447, Val Loss: 0.2702\nEpoch 6/30, Train Loss: 0.3143, Val Loss: 0.2615\nEpoch 7/30, Train Loss: 0.2701, Val Loss: 0.2548\nEpoch 8/30, Train Loss: 0.2378, Val Loss: 0.2528\nEpoch 9/30, Train Loss: 0.2095, Val Loss: 0.2511\nEpoch 10/30, Train Loss: 0.2151, Val Loss: 0.2489\nEpoch 11/30, Train Loss: 0.1775, Val Loss: 0.2479\nEpoch 12/30, Train Loss: 0.1686, Val Loss: 0.2453\nEpoch 13/30, Train Loss: 0.1519, Val Loss: 0.2446\nEpoch 14/30, Train Loss: 0.1495, Val Loss: 0.2429\nEpoch 15/30, Train Loss: 0.1318, Val Loss: 0.2470\nEpoch 16/30, Train Loss: 0.1226, Val Loss: 0.2491\nEpoch 17/30, Train Loss: 0.1137, Val Loss: 0.2491\nEpoch 18/30, Train Loss: 0.1075, Val Loss: 0.2469\nEpoch 19/30, Train Loss: 0.1054, Val Loss: 0.2467\nEarly stopping at epoch 19\nAccuracy: 93.72% ± 3.30%\nPrecision: 93.69% ± 3.31%\nRecall: 93.05% ± 3.47%\nF1-score: 93.08% ± 3.46%\nMacro AUC: 0.9980\nPer-class AUC: 003.backpack: 0.9989, 033.cd: 0.9968, 041.coffee-mug: 0.9997, 047.computer-mouse: 0.9974, 067.eyeglasses: 0.9904, 101.head-phones: 0.9972, 117.ipod: 1.0000, 127.laptop-101: 1.0000, 235.umbrella-101: 0.9997, 240.watch-101: 0.9997\nAverage Inference Time: 0.0002s per image\nFold 3\nEpoch 1/30, Train Loss: 1.7702, Val Loss: 0.9915\nEpoch 2/30, Train Loss: 0.8734, Val Loss: 0.5272\nEpoch 3/30, Train Loss: 0.5536, Val Loss: 0.3794\nEpoch 4/30, Train Loss: 0.4220, Val Loss: 0.3174\nEpoch 5/30, Train Loss: 0.3415, Val Loss: 0.2910\nEpoch 6/30, Train Loss: 0.3123, Val Loss: 0.2736\nEpoch 7/30, Train Loss: 0.2652, Val Loss: 0.2636\nEpoch 8/30, Train Loss: 0.2442, Val Loss: 0.2535\nEpoch 9/30, Train Loss: 0.2168, Val Loss: 0.2451\nEpoch 10/30, Train Loss: 0.1859, Val Loss: 0.2415\nEpoch 11/30, Train Loss: 0.1690, Val Loss: 0.2374\nEpoch 12/30, Train Loss: 0.1770, Val Loss: 0.2336\nEpoch 13/30, Train Loss: 0.1494, Val Loss: 0.2320\nEpoch 14/30, Train Loss: 0.1553, Val Loss: 0.2311\nEpoch 15/30, Train Loss: 0.1385, Val Loss: 0.2298\nEpoch 16/30, Train Loss: 0.1240, Val Loss: 0.2284\nEpoch 17/30, Train Loss: 0.1190, Val Loss: 0.2234\nEpoch 18/30, Train Loss: 0.1154, Val Loss: 0.2210\nEpoch 19/30, Train Loss: 0.1015, Val Loss: 0.2215\nEpoch 20/30, Train Loss: 0.1042, Val Loss: 0.2220\nEpoch 21/30, Train Loss: 0.1180, Val Loss: 0.2227\nEpoch 22/30, Train Loss: 0.0969, Val Loss: 0.2212\nEpoch 23/30, Train Loss: 0.0871, Val Loss: 0.2176\nEpoch 24/30, Train Loss: 0.0853, Val Loss: 0.2141\nEpoch 25/30, Train Loss: 0.0790, Val Loss: 0.2134\nEpoch 26/30, Train Loss: 0.0738, Val Loss: 0.2149\nEpoch 27/30, Train Loss: 0.0696, Val Loss: 0.2158\nEpoch 28/30, Train Loss: 0.0879, Val Loss: 0.2170\nEpoch 29/30, Train Loss: 0.0805, Val Loss: 0.2173\nEpoch 30/30, Train Loss: 0.0668, Val Loss: 0.2173\nEarly stopping at epoch 30\nAccuracy: 92.75% ± 3.53%\nPrecision: 93.21% ± 3.43%\nRecall: 91.26% ± 3.85%\nF1-score: 91.83% ± 3.73%\nMacro AUC: 0.9969\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9916, 041.coffee-mug: 0.9959, 047.computer-mouse: 0.9971, 067.eyeglasses: 0.9904, 101.head-phones: 0.9979, 117.ipod: 0.9977, 127.laptop-101: 0.9995, 235.umbrella-101: 0.9995, 240.watch-101: 0.9998\nAverage Inference Time: 0.0002s per image\nFold 4\nEpoch 1/30, Train Loss: 1.7472, Val Loss: 0.9093\nEpoch 2/30, Train Loss: 0.8636, Val Loss: 0.4289\nEpoch 3/30, Train Loss: 0.5422, Val Loss: 0.2878\nEpoch 4/30, Train Loss: 0.4302, Val Loss: 0.2367\nEpoch 5/30, Train Loss: 0.3384, Val Loss: 0.2100\nEpoch 6/30, Train Loss: 0.2965, Val Loss: 0.1941\nEpoch 7/30, Train Loss: 0.2536, Val Loss: 0.1843\nEpoch 8/30, Train Loss: 0.2295, Val Loss: 0.1792\nEpoch 9/30, Train Loss: 0.2154, Val Loss: 0.1763\nEpoch 10/30, Train Loss: 0.1884, Val Loss: 0.1746\nEpoch 11/30, Train Loss: 0.1861, Val Loss: 0.1746\nEpoch 12/30, Train Loss: 0.1578, Val Loss: 0.1743\nEpoch 13/30, Train Loss: 0.1469, Val Loss: 0.1732\nEpoch 14/30, Train Loss: 0.1303, Val Loss: 0.1730\nEpoch 15/30, Train Loss: 0.1297, Val Loss: 0.1739\nEpoch 16/30, Train Loss: 0.1146, Val Loss: 0.1746\nEpoch 17/30, Train Loss: 0.1122, Val Loss: 0.1759\nEpoch 18/30, Train Loss: 0.0913, Val Loss: 0.1777\nEpoch 19/30, Train Loss: 0.1158, Val Loss: 0.1787\nEarly stopping at epoch 19\nAccuracy: 95.17% ± 2.92%\nPrecision: 94.60% ± 3.08%\nRecall: 95.24% ± 2.90%\nF1-score: 94.84% ± 3.01%\nMacro AUC: 0.9965\nPer-class AUC: 003.backpack: 0.9985, 033.cd: 0.9988, 041.coffee-mug: 0.9993, 047.computer-mouse: 0.9921, 067.eyeglasses: 0.9826, 101.head-phones: 0.9974, 117.ipod: 0.9964, 127.laptop-101: 1.0000, 235.umbrella-101: 1.0000, 240.watch-101: 0.9997\nAverage Inference Time: 0.0003s per image\nFold 5\nEpoch 1/30, Train Loss: 1.8190, Val Loss: 0.9536\nEpoch 2/30, Train Loss: 0.8796, Val Loss: 0.4573\nEpoch 3/30, Train Loss: 0.5670, Val Loss: 0.3187\nEpoch 4/30, Train Loss: 0.4225, Val Loss: 0.2629\nEpoch 5/30, Train Loss: 0.3505, Val Loss: 0.2320\nEpoch 6/30, Train Loss: 0.2906, Val Loss: 0.2143\nEpoch 7/30, Train Loss: 0.2561, Val Loss: 0.2021\nEpoch 8/30, Train Loss: 0.2310, Val Loss: 0.1903\nEpoch 9/30, Train Loss: 0.2089, Val Loss: 0.1811\nEpoch 10/30, Train Loss: 0.1828, Val Loss: 0.1796\nEpoch 11/30, Train Loss: 0.1795, Val Loss: 0.1791\nEpoch 12/30, Train Loss: 0.1682, Val Loss: 0.1773\nEpoch 13/30, Train Loss: 0.1559, Val Loss: 0.1740\nEpoch 14/30, Train Loss: 0.1403, Val Loss: 0.1759\nEpoch 15/30, Train Loss: 0.1310, Val Loss: 0.1719\nEpoch 16/30, Train Loss: 0.1307, Val Loss: 0.1679\nEpoch 17/30, Train Loss: 0.1185, Val Loss: 0.1642\nEpoch 18/30, Train Loss: 0.1086, Val Loss: 0.1653\nEpoch 19/30, Train Loss: 0.1233, Val Loss: 0.1655\nEpoch 20/30, Train Loss: 0.0978, Val Loss: 0.1642\nEpoch 21/30, Train Loss: 0.0912, Val Loss: 0.1632\nEpoch 22/30, Train Loss: 0.0831, Val Loss: 0.1630\nEpoch 23/30, Train Loss: 0.0960, Val Loss: 0.1624\nEpoch 24/30, Train Loss: 0.0899, Val Loss: 0.1620\nEpoch 25/30, Train Loss: 0.0928, Val Loss: 0.1628\nEpoch 26/30, Train Loss: 0.0792, Val Loss: 0.1633\nEpoch 27/30, Train Loss: 0.0713, Val Loss: 0.1619\nEpoch 28/30, Train Loss: 0.0754, Val Loss: 0.1600\nEpoch 29/30, Train Loss: 0.0770, Val Loss: 0.1573\nEpoch 30/30, Train Loss: 0.0656, Val Loss: 0.1549\nAccuracy: 93.24% ± 3.42%\nPrecision: 93.84% ± 3.28%\nRecall: 92.86% ± 3.51%\nF1-score: 92.97% ± 3.48%\nMacro AUC: 0.9987\nPer-class AUC: 003.backpack: 0.9982, 033.cd: 0.9978, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9977, 067.eyeglasses: 0.9989, 101.head-phones: 0.9986, 117.ipod: 0.9982, 127.laptop-101: 0.9983, 235.umbrella-101: 1.0000, 240.watch-101: 0.9997\nAverage Inference Time: 0.0002s per image\n\n5-Fold CV Results:\nAccuracy: 94.11% ± 1.12%\nPrecision: 94.19% ± 0.84%\nRecall: 93.55% ± 1.55%\nF1-score: 93.62% ± 1.31%\nMacro AUC: 0.9976 ± 0.0008\n\nRunning 5-fold CV for resnet50 with augmentation: False\nFold 1\nEpoch 1/30, Train Loss: 1.6193, Val Loss: 0.8569\nEpoch 2/30, Train Loss: 0.6419, Val Loss: 0.4154\nEpoch 3/30, Train Loss: 0.3624, Val Loss: 0.2892\nEpoch 4/30, Train Loss: 0.2455, Val Loss: 0.2344\nEpoch 5/30, Train Loss: 0.1891, Val Loss: 0.2078\nEpoch 6/30, Train Loss: 0.1743, Val Loss: 0.1937\nEpoch 7/30, Train Loss: 0.1442, Val Loss: 0.1831\nEpoch 8/30, Train Loss: 0.1341, Val Loss: 0.1743\nEpoch 9/30, Train Loss: 0.1122, Val Loss: 0.1704\nEpoch 10/30, Train Loss: 0.0875, Val Loss: 0.1590\nEpoch 11/30, Train Loss: 0.0875, Val Loss: 0.1597\nEpoch 12/30, Train Loss: 0.0793, Val Loss: 0.1526\nEpoch 13/30, Train Loss: 0.0775, Val Loss: 0.1480\nEpoch 14/30, Train Loss: 0.0728, Val Loss: 0.1540\nEpoch 15/30, Train Loss: 0.0576, Val Loss: 0.1472\nEpoch 16/30, Train Loss: 0.0511, Val Loss: 0.1428\nEpoch 17/30, Train Loss: 0.0556, Val Loss: 0.1434\nEpoch 18/30, Train Loss: 0.0495, Val Loss: 0.1421\nEpoch 19/30, Train Loss: 0.0504, Val Loss: 0.1439\nEpoch 20/30, Train Loss: 0.0477, Val Loss: 0.1407\nEpoch 21/30, Train Loss: 0.0370, Val Loss: 0.1409\nEpoch 22/30, Train Loss: 0.0345, Val Loss: 0.1330\nEpoch 23/30, Train Loss: 0.0332, Val Loss: 0.1390\nEpoch 24/30, Train Loss: 0.0335, Val Loss: 0.1352\nEpoch 25/30, Train Loss: 0.0302, Val Loss: 0.1309\nEpoch 26/30, Train Loss: 0.0291, Val Loss: 0.1353\nEpoch 27/30, Train Loss: 0.0289, Val Loss: 0.1319\nEpoch 28/30, Train Loss: 0.0245, Val Loss: 0.1287\nEpoch 29/30, Train Loss: 0.0262, Val Loss: 0.1311\nEpoch 30/30, Train Loss: 0.0238, Val Loss: 0.1321\nAccuracy: 95.19% ± 2.91%\nPrecision: 94.68% ± 3.05%\nRecall: 94.54% ± 3.09%\nF1-score: 94.49% ± 3.10%\nMacro AUC: 0.9990\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9971, 041.coffee-mug: 0.9990, 047.computer-mouse: 0.9987, 067.eyeglasses: 0.9996, 101.head-phones: 0.9986, 117.ipod: 0.9965, 127.laptop-101: 1.0000, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 2\nEpoch 1/30, Train Loss: 1.7105, Val Loss: 0.9237\nEpoch 2/30, Train Loss: 0.7248, Val Loss: 0.4314\nEpoch 3/30, Train Loss: 0.3887, Val Loss: 0.3058\nEpoch 4/30, Train Loss: 0.2651, Val Loss: 0.2488\nEpoch 5/30, Train Loss: 0.2138, Val Loss: 0.2095\nEpoch 6/30, Train Loss: 0.1801, Val Loss: 0.1941\nEpoch 7/30, Train Loss: 0.1555, Val Loss: 0.1815\nEpoch 8/30, Train Loss: 0.1400, Val Loss: 0.1663\nEpoch 9/30, Train Loss: 0.1180, Val Loss: 0.1571\nEpoch 10/30, Train Loss: 0.1092, Val Loss: 0.1531\nEpoch 11/30, Train Loss: 0.0939, Val Loss: 0.1515\nEpoch 12/30, Train Loss: 0.0841, Val Loss: 0.1442\nEpoch 13/30, Train Loss: 0.0843, Val Loss: 0.1418\nEpoch 14/30, Train Loss: 0.0784, Val Loss: 0.1324\nEpoch 15/30, Train Loss: 0.0681, Val Loss: 0.1358\nEpoch 16/30, Train Loss: 0.0619, Val Loss: 0.1336\nEpoch 17/30, Train Loss: 0.0608, Val Loss: 0.1292\nEpoch 18/30, Train Loss: 0.0551, Val Loss: 0.1291\nEpoch 19/30, Train Loss: 0.0545, Val Loss: 0.1289\nEpoch 20/30, Train Loss: 0.0460, Val Loss: 0.1233\nEpoch 21/30, Train Loss: 0.0453, Val Loss: 0.1233\nEpoch 22/30, Train Loss: 0.0423, Val Loss: 0.1229\nEpoch 23/30, Train Loss: 0.0406, Val Loss: 0.1243\nEpoch 24/30, Train Loss: 0.0384, Val Loss: 0.1307\nEpoch 25/30, Train Loss: 0.0360, Val Loss: 0.1139\nEpoch 26/30, Train Loss: 0.0306, Val Loss: 0.1323\nEpoch 27/30, Train Loss: 0.0323, Val Loss: 0.1129\nEpoch 28/30, Train Loss: 0.0293, Val Loss: 0.1201\nEpoch 29/30, Train Loss: 0.0271, Val Loss: 0.1153\nEpoch 30/30, Train Loss: 0.0279, Val Loss: 0.1256\nAccuracy: 96.14% ± 2.63%\nPrecision: 95.63% ± 2.78%\nRecall: 95.74% ± 2.75%\nF1-score: 95.58% ± 2.80%\nMacro AUC: 0.9994\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9988, 041.coffee-mug: 0.9997, 047.computer-mouse: 0.9990, 067.eyeglasses: 0.9996, 101.head-phones: 0.9993, 117.ipod: 0.9979, 127.laptop-101: 0.9998, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 3\nEpoch 1/30, Train Loss: 1.7041, Val Loss: 0.9729\nEpoch 2/30, Train Loss: 0.6725, Val Loss: 0.5186\nEpoch 3/30, Train Loss: 0.3507, Val Loss: 0.3670\nEpoch 4/30, Train Loss: 0.2392, Val Loss: 0.3333\nEpoch 5/30, Train Loss: 0.1987, Val Loss: 0.2803\nEpoch 6/30, Train Loss: 0.1652, Val Loss: 0.2643\nEpoch 7/30, Train Loss: 0.1332, Val Loss: 0.2434\nEpoch 8/30, Train Loss: 0.1163, Val Loss: 0.2385\nEpoch 9/30, Train Loss: 0.1010, Val Loss: 0.2278\nEpoch 10/30, Train Loss: 0.1029, Val Loss: 0.2223\nEpoch 11/30, Train Loss: 0.0896, Val Loss: 0.2203\nEpoch 12/30, Train Loss: 0.0793, Val Loss: 0.2132\nEpoch 13/30, Train Loss: 0.0769, Val Loss: 0.2040\nEpoch 14/30, Train Loss: 0.0674, Val Loss: 0.2015\nEpoch 15/30, Train Loss: 0.0560, Val Loss: 0.2030\nEpoch 16/30, Train Loss: 0.0592, Val Loss: 0.2023\nEpoch 17/30, Train Loss: 0.0510, Val Loss: 0.1961\nEpoch 18/30, Train Loss: 0.0481, Val Loss: 0.1930\nEpoch 19/30, Train Loss: 0.0425, Val Loss: 0.1880\nEpoch 20/30, Train Loss: 0.0347, Val Loss: 0.1914\nEpoch 21/30, Train Loss: 0.0379, Val Loss: 0.1871\nEpoch 22/30, Train Loss: 0.0332, Val Loss: 0.1846\nEpoch 23/30, Train Loss: 0.0348, Val Loss: 0.1937\nEpoch 24/30, Train Loss: 0.0335, Val Loss: 0.1817\nEpoch 25/30, Train Loss: 0.0302, Val Loss: 0.1859\nEpoch 26/30, Train Loss: 0.0267, Val Loss: 0.1858\nEpoch 27/30, Train Loss: 0.0253, Val Loss: 0.1802\nEpoch 28/30, Train Loss: 0.0241, Val Loss: 0.1826\nEpoch 29/30, Train Loss: 0.0240, Val Loss: 0.1864\nEpoch 30/30, Train Loss: 0.0218, Val Loss: 0.1733\nAccuracy: 93.72% ± 3.30%\nPrecision: 92.84% ± 3.51%\nRecall: 92.57% ± 3.57%\nF1-score: 92.62% ± 3.56%\nMacro AUC: 0.9975\nPer-class AUC: 003.backpack: 0.9998, 033.cd: 0.9910, 041.coffee-mug: 0.9989, 047.computer-mouse: 0.9961, 067.eyeglasses: 0.9963, 101.head-phones: 0.9981, 117.ipod: 0.9959, 127.laptop-101: 1.0000, 235.umbrella-101: 0.9987, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 4\nEpoch 1/30, Train Loss: 1.5979, Val Loss: 0.8421\nEpoch 2/30, Train Loss: 0.6495, Val Loss: 0.3951\nEpoch 3/30, Train Loss: 0.3586, Val Loss: 0.2819\nEpoch 4/30, Train Loss: 0.2693, Val Loss: 0.2228\nEpoch 5/30, Train Loss: 0.2203, Val Loss: 0.1941\nEpoch 6/30, Train Loss: 0.1557, Val Loss: 0.1763\nEpoch 7/30, Train Loss: 0.1495, Val Loss: 0.1558\nEpoch 8/30, Train Loss: 0.1275, Val Loss: 0.1489\nEpoch 9/30, Train Loss: 0.1117, Val Loss: 0.1398\nEpoch 10/30, Train Loss: 0.1060, Val Loss: 0.1315\nEpoch 11/30, Train Loss: 0.0964, Val Loss: 0.1330\nEpoch 12/30, Train Loss: 0.0851, Val Loss: 0.1236\nEpoch 13/30, Train Loss: 0.0801, Val Loss: 0.1170\nEpoch 14/30, Train Loss: 0.0724, Val Loss: 0.1140\nEpoch 15/30, Train Loss: 0.0661, Val Loss: 0.1148\nEpoch 16/30, Train Loss: 0.0595, Val Loss: 0.1041\nEpoch 17/30, Train Loss: 0.0546, Val Loss: 0.1044\nEpoch 18/30, Train Loss: 0.0540, Val Loss: 0.1038\nEpoch 19/30, Train Loss: 0.0473, Val Loss: 0.1000\nEpoch 20/30, Train Loss: 0.0464, Val Loss: 0.1007\nEpoch 21/30, Train Loss: 0.0458, Val Loss: 0.0986\nEpoch 22/30, Train Loss: 0.0426, Val Loss: 0.0906\nEpoch 23/30, Train Loss: 0.0330, Val Loss: 0.0997\nEpoch 24/30, Train Loss: 0.0369, Val Loss: 0.0930\nEpoch 25/30, Train Loss: 0.0308, Val Loss: 0.0880\nEpoch 26/30, Train Loss: 0.0341, Val Loss: 0.0903\nEpoch 27/30, Train Loss: 0.0280, Val Loss: 0.0875\nEpoch 28/30, Train Loss: 0.0283, Val Loss: 0.0897\nEpoch 29/30, Train Loss: 0.0264, Val Loss: 0.0864\nEpoch 30/30, Train Loss: 0.0334, Val Loss: 0.0942\nAccuracy: 96.14% ± 2.63%\nPrecision: 95.97% ± 2.68%\nRecall: 96.04% ± 2.66%\nF1-score: 95.93% ± 2.69%\nMacro AUC: 0.9997\nPer-class AUC: 003.backpack: 0.9996, 033.cd: 1.0000, 041.coffee-mug: 0.9997, 047.computer-mouse: 0.9993, 067.eyeglasses: 0.9996, 101.head-phones: 0.9991, 117.ipod: 0.9995, 127.laptop-101: 1.0000, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0003s per image\nFold 5\nEpoch 1/30, Train Loss: 1.6335, Val Loss: 0.8573\nEpoch 2/30, Train Loss: 0.6909, Val Loss: 0.4518\nEpoch 3/30, Train Loss: 0.3597, Val Loss: 0.2943\nEpoch 4/30, Train Loss: 0.2457, Val Loss: 0.2393\nEpoch 5/30, Train Loss: 0.1959, Val Loss: 0.2209\nEpoch 6/30, Train Loss: 0.1620, Val Loss: 0.1964\nEpoch 7/30, Train Loss: 0.1635, Val Loss: 0.1840\nEpoch 8/30, Train Loss: 0.1241, Val Loss: 0.1799\nEpoch 9/30, Train Loss: 0.1035, Val Loss: 0.1725\nEpoch 10/30, Train Loss: 0.0961, Val Loss: 0.1726\nEpoch 11/30, Train Loss: 0.0977, Val Loss: 0.1653\nEpoch 12/30, Train Loss: 0.0752, Val Loss: 0.1642\nEpoch 13/30, Train Loss: 0.0673, Val Loss: 0.1549\nEpoch 14/30, Train Loss: 0.0607, Val Loss: 0.1596\nEpoch 15/30, Train Loss: 0.0596, Val Loss: 0.1534\nEpoch 16/30, Train Loss: 0.0592, Val Loss: 0.1495\nEpoch 17/30, Train Loss: 0.0480, Val Loss: 0.1477\nEpoch 18/30, Train Loss: 0.0567, Val Loss: 0.1487\nEpoch 19/30, Train Loss: 0.0454, Val Loss: 0.1516\nEpoch 20/30, Train Loss: 0.0412, Val Loss: 0.1416\nEpoch 21/30, Train Loss: 0.0391, Val Loss: 0.1507\nEpoch 22/30, Train Loss: 0.0463, Val Loss: 0.1403\nEpoch 23/30, Train Loss: 0.0364, Val Loss: 0.1481\nEpoch 24/30, Train Loss: 0.0322, Val Loss: 0.1361\nEpoch 25/30, Train Loss: 0.0338, Val Loss: 0.1469\nEpoch 26/30, Train Loss: 0.0297, Val Loss: 0.1402\nEpoch 27/30, Train Loss: 0.0258, Val Loss: 0.1383\nEpoch 28/30, Train Loss: 0.0254, Val Loss: 0.1444\nEpoch 29/30, Train Loss: 0.0254, Val Loss: 0.1392\nEarly stopping at epoch 29\nAccuracy: 95.17% ± 2.92%\nPrecision: 95.34% ± 2.87%\nRecall: 94.89% ± 3.00%\nF1-score: 94.98% ± 2.98%\nMacro AUC: 0.9985\nPer-class AUC: 003.backpack: 0.9976, 033.cd: 0.9991, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9977, 067.eyeglasses: 0.9993, 101.head-phones: 0.9968, 117.ipod: 0.9972, 127.laptop-101: 0.9980, 235.umbrella-101: 0.9994, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\n\n5-Fold CV Results:\nAccuracy: 95.27% ± 0.89%\nPrecision: 94.89% ± 1.11%\nRecall: 94.75% ± 1.22%\nF1-score: 94.72% ± 1.16%\nMacro AUC: 0.9988 ± 0.0008\n\nRunning 5-fold CV for vgg16 with augmentation: False\nFold 1\nEpoch 1/30, Train Loss: 0.9681, Val Loss: 0.3080\nEpoch 2/30, Train Loss: 0.1927, Val Loss: 0.2254\nEpoch 3/30, Train Loss: 0.1174, Val Loss: 0.1952\nEpoch 4/30, Train Loss: 0.0916, Val Loss: 0.1919\nEpoch 5/30, Train Loss: 0.0654, Val Loss: 0.1903\nEpoch 6/30, Train Loss: 0.0577, Val Loss: 0.1695\nEpoch 7/30, Train Loss: 0.0478, Val Loss: 0.1679\nEpoch 8/30, Train Loss: 0.0364, Val Loss: 0.1612\nEpoch 9/30, Train Loss: 0.0357, Val Loss: 0.1534\nEpoch 10/30, Train Loss: 0.0299, Val Loss: 0.1583\nEpoch 11/30, Train Loss: 0.0296, Val Loss: 0.1604\nEpoch 12/30, Train Loss: 0.0225, Val Loss: 0.1556\nEpoch 13/30, Train Loss: 0.0266, Val Loss: 0.1590\nEpoch 14/30, Train Loss: 0.0212, Val Loss: 0.1532\nEpoch 15/30, Train Loss: 0.0202, Val Loss: 0.1520\nEpoch 16/30, Train Loss: 0.0165, Val Loss: 0.1592\nEpoch 17/30, Train Loss: 0.0166, Val Loss: 0.1709\nEpoch 18/30, Train Loss: 0.0133, Val Loss: 0.1595\nEpoch 19/30, Train Loss: 0.0120, Val Loss: 0.1568\nEpoch 20/30, Train Loss: 0.0110, Val Loss: 0.1667\nEarly stopping at epoch 20\nAccuracy: 95.67% ± 2.77%\nPrecision: 95.60% ± 2.79%\nRecall: 95.23% ± 2.90%\nF1-score: 95.26% ± 2.89%\nMacro AUC: 0.9976\nPer-class AUC: 003.backpack: 0.9993, 033.cd: 0.9994, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9971, 067.eyeglasses: 0.9982, 101.head-phones: 0.9995, 117.ipod: 0.9830, 127.laptop-101: 0.9993, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\nFold 2\nEpoch 1/30, Train Loss: 0.9421, Val Loss: 0.2864\nEpoch 2/30, Train Loss: 0.2141, Val Loss: 0.2088\nEpoch 3/30, Train Loss: 0.1317, Val Loss: 0.1863\nEpoch 4/30, Train Loss: 0.0920, Val Loss: 0.1716\nEpoch 5/30, Train Loss: 0.0646, Val Loss: 0.1655\nEpoch 6/30, Train Loss: 0.0488, Val Loss: 0.1620\nEpoch 7/30, Train Loss: 0.0451, Val Loss: 0.1632\nEpoch 8/30, Train Loss: 0.0416, Val Loss: 0.1656\nEpoch 9/30, Train Loss: 0.0330, Val Loss: 0.1599\nEpoch 10/30, Train Loss: 0.0277, Val Loss: 0.1583\nEpoch 11/30, Train Loss: 0.0285, Val Loss: 0.1592\nEpoch 12/30, Train Loss: 0.0230, Val Loss: 0.1535\nEpoch 13/30, Train Loss: 0.0242, Val Loss: 0.1560\nEpoch 14/30, Train Loss: 0.0207, Val Loss: 0.1507\nEpoch 15/30, Train Loss: 0.0213, Val Loss: 0.1512\nEpoch 16/30, Train Loss: 0.0146, Val Loss: 0.1449\nEpoch 17/30, Train Loss: 0.0169, Val Loss: 0.1430\nEpoch 18/30, Train Loss: 0.0160, Val Loss: 0.1477\nEpoch 19/30, Train Loss: 0.0132, Val Loss: 0.1469\nEpoch 20/30, Train Loss: 0.0136, Val Loss: 0.1462\nEpoch 21/30, Train Loss: 0.0132, Val Loss: 0.1521\nEpoch 22/30, Train Loss: 0.0138, Val Loss: 0.1520\nEarly stopping at epoch 22\nAccuracy: 94.69% ± 3.06%\nPrecision: 94.42% ± 3.13%\nRecall: 94.67% ± 3.06%\nF1-score: 94.46% ± 3.12%\nMacro AUC: 0.9988\nPer-class AUC: 003.backpack: 0.9996, 033.cd: 0.9988, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9990, 067.eyeglasses: 1.0000, 101.head-phones: 0.9974, 117.ipod: 0.9933, 127.laptop-101: 0.9995, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\nFold 3\nEpoch 1/30, Train Loss: 0.9202, Val Loss: 0.3199\nEpoch 2/30, Train Loss: 0.1818, Val Loss: 0.2186\nEpoch 3/30, Train Loss: 0.1105, Val Loss: 0.1980\nEpoch 4/30, Train Loss: 0.0817, Val Loss: 0.2014\nEpoch 5/30, Train Loss: 0.0574, Val Loss: 0.1942\nEpoch 6/30, Train Loss: 0.0473, Val Loss: 0.1949\nEpoch 7/30, Train Loss: 0.0440, Val Loss: 0.1956\nEpoch 8/30, Train Loss: 0.0359, Val Loss: 0.1970\nEpoch 9/30, Train Loss: 0.0408, Val Loss: 0.1942\nEpoch 10/30, Train Loss: 0.0264, Val Loss: 0.1988\nEarly stopping at epoch 10\nAccuracy: 92.75% ± 3.53%\nPrecision: 93.09% ± 3.45%\nRecall: 92.35% ± 3.62%\nF1-score: 92.56% ± 3.57%\nMacro AUC: 0.9979\nPer-class AUC: 003.backpack: 0.9996, 033.cd: 0.9916, 041.coffee-mug: 0.9985, 047.computer-mouse: 1.0000, 067.eyeglasses: 1.0000, 101.head-phones: 0.9929, 117.ipod: 0.9995, 127.laptop-101: 0.9998, 235.umbrella-101: 0.9987, 240.watch-101: 0.9985\nAverage Inference Time: 0.0001s per image\nFold 4\nEpoch 1/30, Train Loss: 0.9586, Val Loss: 0.2437\nEpoch 2/30, Train Loss: 0.1912, Val Loss: 0.1503\nEpoch 3/30, Train Loss: 0.1192, Val Loss: 0.1285\nEpoch 4/30, Train Loss: 0.0922, Val Loss: 0.1253\nEpoch 5/30, Train Loss: 0.0692, Val Loss: 0.1297\nEpoch 6/30, Train Loss: 0.0536, Val Loss: 0.1234\nEpoch 7/30, Train Loss: 0.0478, Val Loss: 0.1237\nEpoch 8/30, Train Loss: 0.0416, Val Loss: 0.1253\nEpoch 9/30, Train Loss: 0.0328, Val Loss: 0.1268\nEpoch 10/30, Train Loss: 0.0302, Val Loss: 0.1300\nEpoch 11/30, Train Loss: 0.0248, Val Loss: 0.1233\nEpoch 12/30, Train Loss: 0.0252, Val Loss: 0.1219\nEpoch 13/30, Train Loss: 0.0228, Val Loss: 0.1227\nEpoch 14/30, Train Loss: 0.0201, Val Loss: 0.1221\nEpoch 15/30, Train Loss: 0.0171, Val Loss: 0.1212\nEpoch 16/30, Train Loss: 0.0212, Val Loss: 0.1219\nEpoch 17/30, Train Loss: 0.0160, Val Loss: 0.1221\nEpoch 18/30, Train Loss: 0.0143, Val Loss: 0.1173\nEpoch 19/30, Train Loss: 0.0138, Val Loss: 0.1167\nEpoch 20/30, Train Loss: 0.0123, Val Loss: 0.1127\nEpoch 21/30, Train Loss: 0.0124, Val Loss: 0.1128\nEpoch 22/30, Train Loss: 0.0119, Val Loss: 0.1188\nEpoch 23/30, Train Loss: 0.0109, Val Loss: 0.1219\nEpoch 24/30, Train Loss: 0.0112, Val Loss: 0.1192\nEpoch 25/30, Train Loss: 0.0099, Val Loss: 0.1143\nEarly stopping at epoch 25\nAccuracy: 96.14% ± 2.63%\nPrecision: 95.67% ± 2.77%\nRecall: 95.32% ± 2.88%\nF1-score: 95.41% ± 2.85%\nMacro AUC: 0.9987\nPer-class AUC: 003.backpack: 0.9996, 033.cd: 0.9975, 041.coffee-mug: 0.9993, 047.computer-mouse: 0.9984, 067.eyeglasses: 0.9985, 101.head-phones: 1.0000, 117.ipod: 0.9946, 127.laptop-101: 1.0000, 235.umbrella-101: 0.9995, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\nFold 5\nEpoch 1/30, Train Loss: 0.9746, Val Loss: 0.2840\nEpoch 2/30, Train Loss: 0.2000, Val Loss: 0.2079\nEpoch 3/30, Train Loss: 0.1127, Val Loss: 0.1868\nEpoch 4/30, Train Loss: 0.0808, Val Loss: 0.1892\nEpoch 5/30, Train Loss: 0.0593, Val Loss: 0.1820\nEpoch 6/30, Train Loss: 0.0518, Val Loss: 0.1709\nEpoch 7/30, Train Loss: 0.0452, Val Loss: 0.1699\nEpoch 8/30, Train Loss: 0.0346, Val Loss: 0.1792\nEpoch 9/30, Train Loss: 0.0323, Val Loss: 0.1740\nEpoch 10/30, Train Loss: 0.0299, Val Loss: 0.1684\nEpoch 11/30, Train Loss: 0.0254, Val Loss: 0.1632\nEpoch 12/30, Train Loss: 0.0195, Val Loss: 0.1639\nEpoch 13/30, Train Loss: 0.0224, Val Loss: 0.1641\nEpoch 14/30, Train Loss: 0.0165, Val Loss: 0.1645\nEpoch 15/30, Train Loss: 0.0197, Val Loss: 0.1618\nEpoch 16/30, Train Loss: 0.0159, Val Loss: 0.1630\nEpoch 17/30, Train Loss: 0.0164, Val Loss: 0.1671\nEpoch 18/30, Train Loss: 0.0158, Val Loss: 0.1686\nEpoch 19/30, Train Loss: 0.0144, Val Loss: 0.1688\nEpoch 20/30, Train Loss: 0.0130, Val Loss: 0.1704\nEarly stopping at epoch 20\nAccuracy: 93.24% ± 3.42%\nPrecision: 92.95% ± 3.49%\nRecall: 93.80% ± 3.28%\nF1-score: 93.16% ± 3.44%\nMacro AUC: 0.9978\nPer-class AUC: 003.backpack: 0.9987, 033.cd: 0.9978, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9997, 067.eyeglasses: 0.9996, 101.head-phones: 0.9943, 117.ipod: 0.9898, 127.laptop-101: 0.9990, 235.umbrella-101: 1.0000, 240.watch-101: 0.9995\nAverage Inference Time: 0.0001s per image\n\n5-Fold CV Results:\nAccuracy: 94.50% ± 1.32%\nPrecision: 94.35% ± 1.17%\nRecall: 94.27% ± 1.11%\nF1-score: 94.17% ± 1.13%\nMacro AUC: 0.9982 ± 0.0005\n\nRunning 5-fold CV for mobilenet_v3 with augmentation: False\nFold 1\nEpoch 1/30, Train Loss: 1.6550, Val Loss: 0.8764\nEpoch 2/30, Train Loss: 0.7011, Val Loss: 0.4340\nEpoch 3/30, Train Loss: 0.4163, Val Loss: 0.3189\nEpoch 4/30, Train Loss: 0.2877, Val Loss: 0.2772\nEpoch 5/30, Train Loss: 0.2289, Val Loss: 0.2573\nEpoch 6/30, Train Loss: 0.1805, Val Loss: 0.2451\nEpoch 7/30, Train Loss: 0.1540, Val Loss: 0.2383\nEpoch 8/30, Train Loss: 0.1351, Val Loss: 0.2332\nEpoch 9/30, Train Loss: 0.1194, Val Loss: 0.2303\nEpoch 10/30, Train Loss: 0.0971, Val Loss: 0.2286\nEpoch 11/30, Train Loss: 0.0968, Val Loss: 0.2301\nEpoch 12/30, Train Loss: 0.0752, Val Loss: 0.2308\nEpoch 13/30, Train Loss: 0.0713, Val Loss: 0.2287\nEpoch 14/30, Train Loss: 0.0690, Val Loss: 0.2278\nEpoch 15/30, Train Loss: 0.0612, Val Loss: 0.2257\nEpoch 16/30, Train Loss: 0.0589, Val Loss: 0.2236\nEpoch 17/30, Train Loss: 0.0537, Val Loss: 0.2215\nEpoch 18/30, Train Loss: 0.0444, Val Loss: 0.2196\nEpoch 19/30, Train Loss: 0.0498, Val Loss: 0.2191\nEpoch 20/30, Train Loss: 0.0388, Val Loss: 0.2181\nEpoch 21/30, Train Loss: 0.0371, Val Loss: 0.2172\nEpoch 22/30, Train Loss: 0.0357, Val Loss: 0.2165\nEpoch 23/30, Train Loss: 0.0308, Val Loss: 0.2152\nEpoch 24/30, Train Loss: 0.0317, Val Loss: 0.2135\nEpoch 25/30, Train Loss: 0.0291, Val Loss: 0.2129\nEpoch 26/30, Train Loss: 0.0290, Val Loss: 0.2120\nEpoch 27/30, Train Loss: 0.0298, Val Loss: 0.2112\nEpoch 28/30, Train Loss: 0.0248, Val Loss: 0.2113\nEpoch 29/30, Train Loss: 0.0242, Val Loss: 0.2107\nEpoch 30/30, Train Loss: 0.0220, Val Loss: 0.2098\nAccuracy: 93.27% ± 3.41%\nPrecision: 93.14% ± 3.44%\nRecall: 92.32% ± 3.62%\nF1-score: 92.60% ± 3.56%\nMacro AUC: 0.9976\nPer-class AUC: 003.backpack: 0.9998, 033.cd: 0.9971, 041.coffee-mug: 0.9993, 047.computer-mouse: 0.9958, 067.eyeglasses: 0.9982, 101.head-phones: 0.9993, 117.ipod: 0.9883, 127.laptop-101: 0.9988, 235.umbrella-101: 1.0000, 240.watch-101: 1.0000\nAverage Inference Time: 0.0003s per image\nFold 2\nEpoch 1/30, Train Loss: 1.7358, Val Loss: 0.9458\nEpoch 2/30, Train Loss: 0.7336, Val Loss: 0.4602\nEpoch 3/30, Train Loss: 0.4174, Val Loss: 0.3368\nEpoch 4/30, Train Loss: 0.3087, Val Loss: 0.2942\nEpoch 5/30, Train Loss: 0.2354, Val Loss: 0.2764\nEpoch 6/30, Train Loss: 0.1916, Val Loss: 0.2730\nEpoch 7/30, Train Loss: 0.1617, Val Loss: 0.2740\nEpoch 8/30, Train Loss: 0.1401, Val Loss: 0.2715\nEpoch 9/30, Train Loss: 0.1247, Val Loss: 0.2731\nEpoch 10/30, Train Loss: 0.1035, Val Loss: 0.2732\nEpoch 11/30, Train Loss: 0.0984, Val Loss: 0.2734\nEpoch 12/30, Train Loss: 0.0881, Val Loss: 0.2722\nEpoch 13/30, Train Loss: 0.0714, Val Loss: 0.2700\nEpoch 14/30, Train Loss: 0.0708, Val Loss: 0.2701\nEpoch 15/30, Train Loss: 0.0625, Val Loss: 0.2695\nEpoch 16/30, Train Loss: 0.0562, Val Loss: 0.2708\nEpoch 17/30, Train Loss: 0.0563, Val Loss: 0.2709\nEpoch 18/30, Train Loss: 0.0525, Val Loss: 0.2712\nEpoch 19/30, Train Loss: 0.0427, Val Loss: 0.2721\nEpoch 20/30, Train Loss: 0.0460, Val Loss: 0.2711\nEarly stopping at epoch 20\nAccuracy: 93.24% ± 3.42%\nPrecision: 92.84% ± 3.51%\nRecall: 92.80% ± 3.52%\nF1-score: 92.76% ± 3.53%\nMacro AUC: 0.9976\nPer-class AUC: 003.backpack: 0.9987, 033.cd: 0.9959, 041.coffee-mug: 0.9993, 047.computer-mouse: 0.9993, 067.eyeglasses: 0.9970, 101.head-phones: 0.9957, 117.ipod: 0.9933, 127.laptop-101: 0.9983, 235.umbrella-101: 0.9980, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 3\nEpoch 1/30, Train Loss: 1.6841, Val Loss: 0.8875\nEpoch 2/30, Train Loss: 0.7173, Val Loss: 0.4644\nEpoch 3/30, Train Loss: 0.4050, Val Loss: 0.3434\nEpoch 4/30, Train Loss: 0.2948, Val Loss: 0.2976\nEpoch 5/30, Train Loss: 0.2285, Val Loss: 0.2749\nEpoch 6/30, Train Loss: 0.1806, Val Loss: 0.2595\nEpoch 7/30, Train Loss: 0.1608, Val Loss: 0.2538\nEpoch 8/30, Train Loss: 0.1364, Val Loss: 0.2459\nEpoch 9/30, Train Loss: 0.1147, Val Loss: 0.2381\nEpoch 10/30, Train Loss: 0.1062, Val Loss: 0.2299\nEpoch 11/30, Train Loss: 0.0920, Val Loss: 0.2231\nEpoch 12/30, Train Loss: 0.0852, Val Loss: 0.2204\nEpoch 13/30, Train Loss: 0.0780, Val Loss: 0.2158\nEpoch 14/30, Train Loss: 0.0717, Val Loss: 0.2123\nEpoch 15/30, Train Loss: 0.0647, Val Loss: 0.2122\nEpoch 16/30, Train Loss: 0.0569, Val Loss: 0.2110\nEpoch 17/30, Train Loss: 0.0460, Val Loss: 0.2079\nEpoch 18/30, Train Loss: 0.0516, Val Loss: 0.2044\nEpoch 19/30, Train Loss: 0.0403, Val Loss: 0.2027\nEpoch 20/30, Train Loss: 0.0440, Val Loss: 0.2015\nEpoch 21/30, Train Loss: 0.0394, Val Loss: 0.1996\nEpoch 22/30, Train Loss: 0.0354, Val Loss: 0.1993\nEpoch 23/30, Train Loss: 0.0315, Val Loss: 0.1986\nEpoch 24/30, Train Loss: 0.0333, Val Loss: 0.1959\nEpoch 25/30, Train Loss: 0.0279, Val Loss: 0.1942\nEpoch 26/30, Train Loss: 0.0282, Val Loss: 0.1933\nEpoch 27/30, Train Loss: 0.0267, Val Loss: 0.1923\nEpoch 28/30, Train Loss: 0.0245, Val Loss: 0.1925\nEpoch 29/30, Train Loss: 0.0262, Val Loss: 0.1920\nEpoch 30/30, Train Loss: 0.0232, Val Loss: 0.1912\nAccuracy: 93.24% ± 3.42%\nPrecision: 93.37% ± 3.39%\nRecall: 91.71% ± 3.76%\nF1-score: 92.02% ± 3.69%\nMacro AUC: 0.9984\nPer-class AUC: 003.backpack: 0.9985, 033.cd: 0.9910, 041.coffee-mug: 0.9989, 047.computer-mouse: 1.0000, 067.eyeglasses: 0.9993, 101.head-phones: 0.9983, 117.ipod: 0.9987, 127.laptop-101: 1.0000, 235.umbrella-101: 0.9995, 240.watch-101: 1.0000\nAverage Inference Time: 0.0002s per image\nFold 4\nEpoch 1/30, Train Loss: 1.7248, Val Loss: 0.8769\nEpoch 2/30, Train Loss: 0.7325, Val Loss: 0.4077\nEpoch 3/30, Train Loss: 0.4124, Val Loss: 0.2806\nEpoch 4/30, Train Loss: 0.3017, Val Loss: 0.2376\nEpoch 5/30, Train Loss: 0.2276, Val Loss: 0.2166\nEpoch 6/30, Train Loss: 0.1944, Val Loss: 0.2050\nEpoch 7/30, Train Loss: 0.1608, Val Loss: 0.2001\nEpoch 8/30, Train Loss: 0.1285, Val Loss: 0.1971\nEpoch 9/30, Train Loss: 0.1148, Val Loss: 0.1972\nEpoch 10/30, Train Loss: 0.1017, Val Loss: 0.1975\nEpoch 11/30, Train Loss: 0.0909, Val Loss: 0.1979\nEpoch 12/30, Train Loss: 0.0809, Val Loss: 0.1993\nEpoch 13/30, Train Loss: 0.0725, Val Loss: 0.1986\nEarly stopping at epoch 13\nAccuracy: 94.20% ± 3.18%\nPrecision: 93.67% ± 3.32%\nRecall: 94.31% ± 3.16%\nF1-score: 93.83% ± 3.28%\nMacro AUC: 0.9977\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9997, 041.coffee-mug: 0.9990, 047.computer-mouse: 0.9918, 067.eyeglasses: 0.9889, 101.head-phones: 1.0000, 117.ipod: 0.9974, 127.laptop-101: 1.0000, 235.umbrella-101: 1.0000, 240.watch-101: 0.9998\nAverage Inference Time: 0.0002s per image\nFold 5\nEpoch 1/30, Train Loss: 1.7207, Val Loss: 0.8046\nEpoch 2/30, Train Loss: 0.7323, Val Loss: 0.3939\nEpoch 3/30, Train Loss: 0.4150, Val Loss: 0.2828\nEpoch 4/30, Train Loss: 0.2943, Val Loss: 0.2402\nEpoch 5/30, Train Loss: 0.2212, Val Loss: 0.2151\nEpoch 6/30, Train Loss: 0.1862, Val Loss: 0.1999\nEpoch 7/30, Train Loss: 0.1637, Val Loss: 0.1917\nEpoch 8/30, Train Loss: 0.1424, Val Loss: 0.1864\nEpoch 9/30, Train Loss: 0.1184, Val Loss: 0.1852\nEpoch 10/30, Train Loss: 0.1022, Val Loss: 0.1836\nEpoch 11/30, Train Loss: 0.0937, Val Loss: 0.1829\nEpoch 12/30, Train Loss: 0.0889, Val Loss: 0.1840\nEpoch 13/30, Train Loss: 0.0751, Val Loss: 0.1829\nEpoch 14/30, Train Loss: 0.0682, Val Loss: 0.1822\nEpoch 15/30, Train Loss: 0.0640, Val Loss: 0.1819\nEpoch 16/30, Train Loss: 0.0526, Val Loss: 0.1807\nEpoch 17/30, Train Loss: 0.0547, Val Loss: 0.1796\nEpoch 18/30, Train Loss: 0.0471, Val Loss: 0.1791\nEpoch 19/30, Train Loss: 0.0444, Val Loss: 0.1797\nEpoch 20/30, Train Loss: 0.0439, Val Loss: 0.1796\nEpoch 21/30, Train Loss: 0.0382, Val Loss: 0.1787\nEpoch 22/30, Train Loss: 0.0376, Val Loss: 0.1781\nEpoch 23/30, Train Loss: 0.0349, Val Loss: 0.1771\nEpoch 24/30, Train Loss: 0.0287, Val Loss: 0.1756\nEpoch 25/30, Train Loss: 0.0295, Val Loss: 0.1749\nEpoch 26/30, Train Loss: 0.0270, Val Loss: 0.1747\nEpoch 27/30, Train Loss: 0.0313, Val Loss: 0.1748\nEpoch 28/30, Train Loss: 0.0245, Val Loss: 0.1735\nEpoch 29/30, Train Loss: 0.0243, Val Loss: 0.1730\nEpoch 30/30, Train Loss: 0.0223, Val Loss: 0.1728\nAccuracy: 92.27% ± 3.64%\nPrecision: 92.58% ± 3.57%\nRecall: 91.96% ± 3.70%\nF1-score: 92.12% ± 3.67%\nMacro AUC: 0.9981\nPer-class AUC: 003.backpack: 0.9974, 033.cd: 0.9966, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9964, 067.eyeglasses: 1.0000, 101.head-phones: 0.9984, 117.ipod: 0.9969, 127.laptop-101: 0.9985, 235.umbrella-101: 0.9994, 240.watch-101: 0.9974\nAverage Inference Time: 0.0002s per image\n\n5-Fold CV Results:\nAccuracy: 93.24% ± 0.61%\nPrecision: 93.12% ± 0.38%\nRecall: 92.62% ± 0.92%\nF1-score: 92.66% ± 0.64%\nMacro AUC: 0.9979 ± 0.0003\n\nTraining final model (ResNet50) on full train+val and evaluating on test/noise test\nFinal Train Epoch 1, Loss: 1.7082\nFinal Train Epoch 2, Loss: 0.8126\nFinal Train Epoch 3, Loss: 0.5266\nFinal Train Epoch 4, Loss: 0.4251\nFinal Train Epoch 5, Loss: 0.3232\nFinal Train Epoch 6, Loss: 0.3000\nFinal Train Epoch 7, Loss: 0.3001\nFinal Train Epoch 8, Loss: 0.2514\nFinal Train Epoch 9, Loss: 0.2397\nFinal Train Epoch 10, Loss: 0.2309\nFinal Train Epoch 11, Loss: 0.1924\nFinal Train Epoch 12, Loss: 0.1783\nFinal Train Epoch 13, Loss: 0.1701\nFinal Train Epoch 14, Loss: 0.2110\nFinal Train Epoch 15, Loss: 0.1829\nFinal Train Epoch 16, Loss: 0.1611\nFinal Train Epoch 17, Loss: 0.1419\nFinal Train Epoch 18, Loss: 0.1718\nFinal Train Epoch 19, Loss: 0.1377\nFinal Train Epoch 20, Loss: 0.1331\n\nHoldout Test Evaluation:\nAccuracy: 93.44% ± 3.59%\nPrecision: 93.64% ± 3.54%\nRecall: 92.70% ± 3.77%\nF1-score: 92.71% ± 3.77%\nMacro AUC: 0.9946\nPer-class AUC: 003.backpack: 1.0000, 033.cd: 0.9893, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9962, 067.eyeglasses: 1.0000, 101.head-phones: 0.9697, 117.ipod: 0.9960, 127.laptop-101: 0.9981, 235.umbrella-101: 0.9972, 240.watch-101: 1.0000\nAverage Inference Time: 0.0003s per image\n\nNoise Test Evaluation (Robustness to Gaussian Blur):\nAccuracy: 93.99% ± 3.44%\nPrecision: 93.97% ± 3.45%\nRecall: 93.23% ± 3.64%\nF1-score: 93.15% ± 3.66%\nMacro AUC: 0.9922\nPer-class AUC: 003.backpack: 0.9997, 033.cd: 0.9897, 041.coffee-mug: 1.0000, 047.computer-mouse: 0.9869, 067.eyeglasses: 1.0000, 101.head-phones: 0.9603, 117.ipod: 0.9909, 127.laptop-101: 0.9981, 235.umbrella-101: 0.9968, 240.watch-101: 1.0000\nAverage Inference Time: 0.0001s per image\n\nGenerated PNG files:\naug_mobilenet_v3_fold1_confusion_matrix_300dpi.png\naug_mobilenet_v3_fold1_learning_curve_300dpi.png\naug_mobilenet_v3_fold1_per_class_metrics_300dpi.png\naug_mobilenet_v3_fold1_roc_curves_300dpi.png\naug_mobilenet_v3_fold2_confusion_matrix_300dpi.png\naug_mobilenet_v3_fold2_learning_curve_300dpi.png\naug_mobilenet_v3_fold2_per_class_metrics_300dpi.png\naug_mobilenet_v3_fold2_roc_curves_300dpi.png\naug_mobilenet_v3_fold3_confusion_matrix_300dpi.png\naug_mobilenet_v3_fold3_learning_curve_300dpi.png\naug_mobilenet_v3_fold3_per_class_metrics_300dpi.png\naug_mobilenet_v3_fold3_roc_curves_300dpi.png\naug_mobilenet_v3_fold4_confusion_matrix_300dpi.png\naug_mobilenet_v3_fold4_learning_curve_300dpi.png\naug_mobilenet_v3_fold4_per_class_metrics_300dpi.png\naug_mobilenet_v3_fold4_roc_curves_300dpi.png\naug_mobilenet_v3_fold5_confusion_matrix_300dpi.png\naug_mobilenet_v3_fold5_learning_curve_300dpi.png\naug_mobilenet_v3_fold5_per_class_metrics_300dpi.png\naug_mobilenet_v3_fold5_roc_curves_300dpi.png\naug_resnet50_fold1_confusion_matrix_300dpi.png\naug_resnet50_fold1_learning_curve_300dpi.png\naug_resnet50_fold1_per_class_metrics_300dpi.png\naug_resnet50_fold1_roc_curves_300dpi.png\naug_resnet50_fold2_confusion_matrix_300dpi.png\naug_resnet50_fold2_learning_curve_300dpi.png\naug_resnet50_fold2_per_class_metrics_300dpi.png\naug_resnet50_fold2_roc_curves_300dpi.png\naug_resnet50_fold3_confusion_matrix_300dpi.png\naug_resnet50_fold3_learning_curve_300dpi.png\naug_resnet50_fold3_per_class_metrics_300dpi.png\naug_resnet50_fold3_roc_curves_300dpi.png\naug_resnet50_fold4_confusion_matrix_300dpi.png\naug_resnet50_fold4_learning_curve_300dpi.png\naug_resnet50_fold4_per_class_metrics_300dpi.png\naug_resnet50_fold4_roc_curves_300dpi.png\naug_resnet50_fold5_confusion_matrix_300dpi.png\naug_resnet50_fold5_learning_curve_300dpi.png\naug_resnet50_fold5_per_class_metrics_300dpi.png\naug_resnet50_fold5_roc_curves_300dpi.png\naug_vgg16_fold1_confusion_matrix_300dpi.png\naug_vgg16_fold1_learning_curve_300dpi.png\naug_vgg16_fold1_per_class_metrics_300dpi.png\naug_vgg16_fold1_roc_curves_300dpi.png\naug_vgg16_fold2_confusion_matrix_300dpi.png\naug_vgg16_fold2_learning_curve_300dpi.png\naug_vgg16_fold2_per_class_metrics_300dpi.png\naug_vgg16_fold2_roc_curves_300dpi.png\naug_vgg16_fold3_confusion_matrix_300dpi.png\naug_vgg16_fold3_learning_curve_300dpi.png\naug_vgg16_fold3_per_class_metrics_300dpi.png\naug_vgg16_fold3_roc_curves_300dpi.png\naug_vgg16_fold4_confusion_matrix_300dpi.png\naug_vgg16_fold4_learning_curve_300dpi.png\naug_vgg16_fold4_per_class_metrics_300dpi.png\naug_vgg16_fold4_roc_curves_300dpi.png\naug_vgg16_fold5_confusion_matrix_300dpi.png\naug_vgg16_fold5_learning_curve_300dpi.png\naug_vgg16_fold5_per_class_metrics_300dpi.png\naug_vgg16_fold5_roc_curves_300dpi.png\nfinal_test_confusion_matrix_300dpi.png\nfinal_test_per_class_metrics_300dpi.png\nfinal_test_roc_curves_300dpi.png\nnoaug_mobilenet_v3_fold1_confusion_matrix_300dpi.png\nnoaug_mobilenet_v3_fold1_learning_curve_300dpi.png\nnoaug_mobilenet_v3_fold1_per_class_metrics_300dpi.png\nnoaug_mobilenet_v3_fold1_roc_curves_300dpi.png\nnoaug_mobilenet_v3_fold2_confusion_matrix_300dpi.png\nnoaug_mobilenet_v3_fold2_learning_curve_300dpi.png\nnoaug_mobilenet_v3_fold2_per_class_metrics_300dpi.png\nnoaug_mobilenet_v3_fold2_roc_curves_300dpi.png\nnoaug_mobilenet_v3_fold3_confusion_matrix_300dpi.png\nnoaug_mobilenet_v3_fold3_learning_curve_300dpi.png\nnoaug_mobilenet_v3_fold3_per_class_metrics_300dpi.png\nnoaug_mobilenet_v3_fold3_roc_curves_300dpi.png\nnoaug_mobilenet_v3_fold4_confusion_matrix_300dpi.png\nnoaug_mobilenet_v3_fold4_learning_curve_300dpi.png\nnoaug_mobilenet_v3_fold4_per_class_metrics_300dpi.png\nnoaug_mobilenet_v3_fold4_roc_curves_300dpi.png\nnoaug_mobilenet_v3_fold5_confusion_matrix_300dpi.png\nnoaug_mobilenet_v3_fold5_learning_curve_300dpi.png\nnoaug_mobilenet_v3_fold5_per_class_metrics_300dpi.png\nnoaug_mobilenet_v3_fold5_roc_curves_300dpi.png\nnoaug_resnet50_fold1_confusion_matrix_300dpi.png\nnoaug_resnet50_fold1_learning_curve_300dpi.png\nnoaug_resnet50_fold1_per_class_metrics_300dpi.png\nnoaug_resnet50_fold1_roc_curves_300dpi.png\nnoaug_resnet50_fold2_confusion_matrix_300dpi.png\nnoaug_resnet50_fold2_learning_curve_300dpi.png\nnoaug_resnet50_fold2_per_class_metrics_300dpi.png\nnoaug_resnet50_fold2_roc_curves_300dpi.png\nnoaug_resnet50_fold3_confusion_matrix_300dpi.png\nnoaug_resnet50_fold3_learning_curve_300dpi.png\nnoaug_resnet50_fold3_per_class_metrics_300dpi.png\nnoaug_resnet50_fold3_roc_curves_300dpi.png\nnoaug_resnet50_fold4_confusion_matrix_300dpi.png\nnoaug_resnet50_fold4_learning_curve_300dpi.png\nnoaug_resnet50_fold4_per_class_metrics_300dpi.png\nnoaug_resnet50_fold4_roc_curves_300dpi.png\nnoaug_resnet50_fold5_confusion_matrix_300dpi.png\nnoaug_resnet50_fold5_learning_curve_300dpi.png\nnoaug_resnet50_fold5_per_class_metrics_300dpi.png\nnoaug_resnet50_fold5_roc_curves_300dpi.png\nnoaug_vgg16_fold1_confusion_matrix_300dpi.png\nnoaug_vgg16_fold1_learning_curve_300dpi.png\nnoaug_vgg16_fold1_per_class_metrics_300dpi.png\nnoaug_vgg16_fold1_roc_curves_300dpi.png\nnoaug_vgg16_fold2_confusion_matrix_300dpi.png\nnoaug_vgg16_fold2_learning_curve_300dpi.png\nnoaug_vgg16_fold2_per_class_metrics_300dpi.png\nnoaug_vgg16_fold2_roc_curves_300dpi.png\nnoaug_vgg16_fold3_confusion_matrix_300dpi.png\nnoaug_vgg16_fold3_learning_curve_300dpi.png\nnoaug_vgg16_fold3_per_class_metrics_300dpi.png\nnoaug_vgg16_fold3_roc_curves_300dpi.png\nnoaug_vgg16_fold4_confusion_matrix_300dpi.png\nnoaug_vgg16_fold4_learning_curve_300dpi.png\nnoaug_vgg16_fold4_per_class_metrics_300dpi.png\nnoaug_vgg16_fold4_roc_curves_300dpi.png\nnoaug_vgg16_fold5_confusion_matrix_300dpi.png\nnoaug_vgg16_fold5_learning_curve_300dpi.png\nnoaug_vgg16_fold5_per_class_metrics_300dpi.png\nnoaug_vgg16_fold5_roc_curves_300dpi.png\nnoise_test_confusion_matrix_300dpi.png\nnoise_test_per_class_metrics_300dpi.png\nnoise_test_roc_curves_300dpi.png\n","output_type":"stream"}],"execution_count":8}]}